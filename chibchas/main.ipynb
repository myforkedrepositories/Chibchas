{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incorrect-retailer",
   "metadata": {},
   "source": [
    "# Institulac "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "brilliant-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"max_rows\",100)\n",
    "#pd.set_option(\"display.max_columns\",100)\n",
    "pd.set_option(\"max_colwidth\",1000)\n",
    "\n",
    "import helium as h\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "everyday-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICT CAT-PRODS-TAB\n",
    "with open('dict_tables.json') as file_json:\n",
    "    dict_tables=json.loads(file_json.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "polyphonic-queens",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Nombre del grupo', 'Nombre del líder', 'COL Grupo', 'Revisar'], dtype='object') (100, 4)\n",
      "Index(['Nombre del grupo', 'Nombre del líder', 'COL Grupo', 'Revisar'], dtype='object') (100, 4)\n",
      "Index(['Nombre del grupo', 'Nombre del líder', 'COL Grupo', 'Revisar'], dtype='object') (100, 4)\n",
      "Index(['Nombre del grupo', 'Nombre del líder', 'COL Grupo', 'Revisar'], dtype='object') (24, 4)\n",
      "Message: Unable to locate element: //table[@id=\"grupos_avalados\"]//tr/td[3]/a\n",
      "\n",
      "out of cicle\n"
     ]
    }
   ],
   "source": [
    "# login =\n",
    "# name_ins =\n",
    "# usser =\n",
    "# passw=\n",
    "\n",
    "# login\n",
    "browser = h.start_firefox('https://scienti.minciencias.gov.co/institulac2-war/')\n",
    "sleep=0.8\n",
    "\n",
    "#browser = h.start_firefox('https://scienti.minciencias.gov.co/institulac2-war/')\n",
    "time.sleep(sleep)\n",
    "h.click('Consulte Aquí')\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.write('UNIVERSIDAD DE ANTIOQUIA',into='Digite el nombre de la Institución') # name ins\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.click('Buscar')\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.click(browser.find_element_by_id('list_instituciones'))\n",
    "\n",
    "time.sleep(sleep)\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.select('seleccione una','UNIVERSIDAD DE ANTIOQUIA') # name_ins\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.write('annyarango',into='Usuario')                  # user\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.write('1@Silver', into='Contraseña')                # passw\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.click(h.Button('Ingresar'))\n",
    "\n",
    "# cookie injection\n",
    "time.sleep(sleep)\n",
    "# implementation cookie injection\n",
    "\n",
    "# get current cookie and store\n",
    "new_cookie=browser.get_cookies()[0]\n",
    "    \n",
    "# create new_cookie with time_expire\n",
    "time_expire = (datetime(2022,1,1) - datetime(1970,1,1)).total_seconds()\n",
    "new_cookie['expiry'] = int(time_expire)\n",
    "    \n",
    "# delete cookie sites\n",
    "browser.delete_all_cookies()\n",
    "    \n",
    "# add new cookie\n",
    "browser.add_cookie(new_cookie)\n",
    "\n",
    "# navigation 1\n",
    "time.sleep(sleep)\n",
    "h.click('Aval')\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.click('Avalar grupos')\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.click('Grupos Avalados')\n",
    "\n",
    "# -- end login --\n",
    "\n",
    "# list of total groups\n",
    "#select max results per page\n",
    "h.wait_until(h.Text('Ver Reporte').exists)\n",
    "h.click(browser.find_element_by_xpath('//table[@id=\"grupos_avalados\"]//select[@name=\"maxRows\"]'))\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.select(browser.find_element_by_xpath('//table[@id=\"grupos_avalados\"]//select[@name=\"maxRows\"]'),'100')\n",
    "\n",
    "# catch 1: groups info [name, lider, cod,  link to producs]  \n",
    "# schema\n",
    "# empty df\n",
    "# select max items per page\n",
    "# while until end\n",
    "# try:\n",
    "    # catch table\n",
    "    # preproces table\n",
    "    # catch urls\n",
    "    # add url colums\n",
    "    # add df\n",
    "    # click next page -> raise error\n",
    "# except Nosuchelement:\n",
    "    # break\n",
    "    \n",
    "# catch 1: list of groups\n",
    "dfg=pd.DataFrame()\n",
    "cont=True\n",
    "\n",
    "while cont:\n",
    "    \n",
    "    try:\n",
    "        # catch source\n",
    "        time.sleep(sleep)\n",
    "        source_g=browser.page_source\n",
    "        \n",
    "        # catch table\n",
    "        time.sleep(sleep)\n",
    "        df=pd.read_html(source_g, attrs={\"id\":\"grupos_avalados\"}, header=2)[0]\n",
    "        \n",
    "        # and preprocces it\n",
    "        c=[x for x in df.columns if x.find('Unnamed:') == -1]\n",
    "        dfgp=df[c][1:-1]\n",
    "        print(dfgp.columns,dfgp.shape)\n",
    "        \n",
    "        # catch urls\n",
    "        url=[a.get_attribute('href') for a in browser.find_elements_by_xpath('//table[@id=\"grupos_avalados\"]//td[5]/a')]\n",
    "        dfgp['Revisar'] = url\n",
    "        dfg=dfg.append(dfgp)\n",
    "        \n",
    "        # click next page. this instruction rise error of the end. \n",
    "        h.click(browser.find_element_by_xpath('//table[@id=\"grupos_avalados\"]//tr/td[3]/a'))\n",
    "        \n",
    "    except NoSuchElementException as e:\n",
    "        \n",
    "        print(e)\n",
    "        print('out of cicle')\n",
    "        break\n",
    "        \n",
    "    time.sleep(sleep)\n",
    "    time.sleep(sleep)\n",
    "    \n",
    "dfg = dfg.reset_index(drop=True)\n",
    "assert dfg.shape[0] == 324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "circular-conservation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grupo Tandem en Nano-bio-física \n",
      " https://scienti.minciencias.gov.co/institulac2-war/ReGrupoInstitucion/query.do?avalGr=T&codigoGrupo=&idGrupo=00000000020456\n",
      "Promoción de la Salud \n",
      " https://scienti.minciencias.gov.co/institulac2-war/ReGrupoInstitucion/query.do?avalGr=T&codigoGrupo=&idGrupo=00000000001767\n"
     ]
    }
   ],
   "source": [
    "print(dfg['Nombre del grupo'][0:1].values[0],'\\n',dfg['Revisar'][:1].values[0])\n",
    "\n",
    "print(dfg['Nombre del grupo'][-1:].values[0],'\\n',dfg['Revisar'][-1:].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "endangered-velvet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    Micología Médica\n",
       "Name: Nombre del grupo, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg['Nombre del grupo'][3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "literary-washington",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micología Médica\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=NC_P&subcategoriaP=ART_IMP_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=NC_P&subcategoriaP=ART_ELE_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=NC_P&subcategoriaP=LIB_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=NC_P&subcategoriaP=CAP_LIB_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=NC_P&subcategoriaP=NOT_CIE_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=NC_P&subcategoriaP=PAT_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=NC_P&subcategoriaP=PRD_INV_ART_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=NC_P&subcategoriaP=VAR_VEG_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=NC_P&subcategoriaP=VAR_ANI_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=NC_P&subcategoriaP=RAZ_PEC_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=NC_P&subcategoriaP=TRA_FIL_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=DIS_IND_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=CIR_INT_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=SOFT_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=NUTRA_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=COL_CIENT_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=REG_CIENT_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=PLT_PIL_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=PRT_IND_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=SEC_IND_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=PROT_VIG_EPID_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=EMP_BSE_TEC_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=EMP_CRE_CUL_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=INN_GES_EMP_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=INN_PROC_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=REG_NORM_REGL_LEG_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=CONP_TEC_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=REG_AAD_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=DTI_P&subcategoriaP=SIG_DIS_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=ASC_P&subcategoriaP=EV_CIENT_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=ASC_P&subcategoriaP=RED_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=ASC_P&subcategoriaP=TALL_CRE_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=ASC_P&subcategoriaP=EVE_ART_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=ASC_P&subcategoriaP=DOC_TRAB_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=ASC_P&subcategoriaP=SEC_GENE_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=ASC_P&subcategoriaP=BOL_RES_INV_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=ASC_P&subcategoriaP=CON_INF_TEC_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=ASC_P&subcategoriaP=EDIC_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=FRH_P&subcategoriaP=TES_DOC_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=FRH_P&subcategoriaP=TES_MAST_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=FRH_P&subcategoriaP=TES_PREG_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=FRH_P&subcategoriaP=PROY_INV_DES_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=FRH_P&subcategoriaP=PROY_INV_CRE_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=FRH_P&subcategoriaP=PROY_INV_DES_INN_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=FRH_P&subcategoriaP=PROY_INV_RESP_SOC_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=FRH_P&subcategoriaP=ASE_PRG_ACA_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=FRH_P&subcategoriaP=ASE_CRE_CUR_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoriaP=FRH_P&subcategoriaP=ASE_PRG_ONDAS_P&aval=P&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoria=NC&subcategoria=LIB&aval=T&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n",
      "https://scienti.minciencias.gov.co/institulac2-war/verificador/allproductosGr.do?categoria=NC&subcategoria=CAP_LIB&aval=T&idGrupo=00000000002499&avalGr=T&codigoGrupo=&grCAv=1&nmeGrupo=Micolog%EDa%20M%E9dica&codIdGrupo=COL0042069\n"
     ]
    }
   ],
   "source": [
    "time.sleep(sleep*2)\n",
    "\n",
    "DB = [] # \n",
    "LP = []\n",
    "LR = [] \n",
    "for idx in dfg.index[3:4]:\n",
    "    \n",
    "    # create db for store things related to group\n",
    "    DBG = {}\n",
    "    \n",
    "    # part info group\n",
    "    print(dfg.loc[idx,'Nombre del grupo'])\n",
    "\n",
    "    # specific group url\n",
    "    time.sleep(sleep)\n",
    "    url_group = dfg.loc[idx,'Revisar']\n",
    "\n",
    "    # go to url group\n",
    "    time.sleep(sleep)\n",
    "    browser.get(url_group)\n",
    "\n",
    "    # catch two tables: info grupo and  members\n",
    "    source=browser.page_source\n",
    "\n",
    "    #info\n",
    "    l_info=pd.read_html(source, match='Nombre Grupo')\n",
    "    info_g=l_info[3].pivot(columns=0,values=1)\n",
    "    \n",
    "    # STORE INFO_GROUP\n",
    "    DBG['Info_group'] = info_g\n",
    "\n",
    "    # members\n",
    "    l_int = pd.read_html(source,attrs={'id':'tblIntegrantes'},header=2)\n",
    "    mem_g=l_int[0]\n",
    "    \n",
    "    # STORE_MEMBERS\n",
    "    DBG['Members'] =  mem_g\n",
    "\n",
    "    # Products\n",
    "\n",
    "    #time.sleep(sleep*5) # time time time !!!\n",
    "    h.wait_until(lambda: browser.find_element_by_xpath('//td[@id=\"bodyPrincipal\"]//a[text()=\"Ver productos\"]') is not None)\n",
    "    h.click(browser.find_element_by_xpath('//td[@id=\"bodyPrincipal\"]//a[text()=\"Ver productos\"]'))\n",
    "\n",
    "    # products by belongs to  # time time time\n",
    "    #time.sleep(sleep*7)       # time time time\n",
    "    h.wait_until(lambda: browser.find_element_by_xpath('//*[@id=\"ProdsPertenecia\"]') is not None)\n",
    "    h.click(browser.find_element_by_xpath('//*[@id=\"ProdsPertenecia\"]'))\n",
    "\n",
    "    time.sleep(sleep)\n",
    "    url_products=browser.current_url\n",
    "\n",
    "\n",
    "    # map all products, store those id categories that amount is different to 0 and id products asociated.\n",
    "    # make queries with combinations of categories and products\n",
    "    # make urls with diferent combinations of quieries\n",
    "    # go to each of urls\n",
    "    # load page source\n",
    "    # catch table ( or tables) asociated with categories and products\n",
    "    # store tables\n",
    "\n",
    "    report = ''\n",
    "\n",
    "    list_of_prods =[] #[[cat,prod],[cat,prod]...]\n",
    "\n",
    "    # map all products and get products and subs diff to cero\n",
    "    for i in browser.find_elements_by_xpath('//div[@id=\"accordionCatgP\"]/h3'):\n",
    "\n",
    "        report += i.text + '\\n' \n",
    "        report += i.get_attribute('id') + '\\n'     \n",
    "\n",
    "        time.sleep(sleep)\n",
    "        h.click(i)\n",
    "        \n",
    "        # cat\n",
    "        cat_ = int(re.findall(r'\\d+',i.text)[0])\n",
    "        \n",
    "        # create cat key in dict, for estore diferents products by this categori: 'NC_': {'ART_E':TABLE,\n",
    "        #                                                                                 'ART_IMP':TABLE}\n",
    "        #if cat_ > 0:\n",
    "        DBG[i.get_attribute('id')] = {}\n",
    "            \n",
    "        \n",
    "        for j in browser.find_elements_by_xpath('//div[@aria-labelledby=\"%s\"]/h3' % i.get_attribute('id')):\n",
    "\n",
    "            report += '\\t' + j.text + '\\n' \n",
    "            report += '\\t' + j.get_attribute('id') + '\\n'\n",
    "            \n",
    "            #prod\n",
    "            pro_ = int(re.findall(r'\\d+', j.text)[0])\n",
    "\n",
    "            #if cat_ > 0 and pro_ > 0:  \n",
    "                \n",
    "            list_of_prods.append([i.get_attribute('id'),j.get_attribute('id')])\n",
    "\n",
    "        time.sleep(sleep) \n",
    "        # h.click(a)\n",
    "        h.click(i)\n",
    "    \n",
    "    # PAR: products with revisions\n",
    "    h.wait_until(lambda: browser.find_element_by_xpath('//*[@id=\"ProdsAval\"]'))\n",
    "    h.click(browser.find_element_by_xpath('//*[@id=\"ProdsAval\"]'))\n",
    "\n",
    "    # NC\n",
    "\n",
    "    _NC = browser.find_element_by_xpath('//*[@id=\"NC\"]')\n",
    "\n",
    "    h.click(_NC)\n",
    "\n",
    "    cat_ = int(re.findall(r'\\d+',_NC.text)[0])\n",
    "\n",
    "    LIB = browser.find_element_by_xpath('//*[@id=\"LIB\"]')\n",
    "\n",
    "    L = int(re.findall(r'\\d+', LIB.text)[0])\n",
    "\n",
    "    CAP_LIB = browser.find_element_by_xpath('//*[@id=\"CAP_LIB\"]')\n",
    "\n",
    "    CL = int(re.findall(r'\\d+', CAP_LIB.text)[0])\n",
    "\n",
    "    #if (cat_ > 0 and L > 0) or (cat_ > 0 and CL > 0):\n",
    "\n",
    "    DBG[_NC.get_attribute('id')] = {}\n",
    "        \n",
    "    #if (cat_ > 0 and L > 0):\n",
    "        \n",
    "    list_of_prods.append([_NC.get_attribute('id'),LIB.get_attribute('id')])\n",
    "    \n",
    "    #if (cat_ > 0 and CL > 0):\n",
    "        \n",
    "    list_of_prods.append([_NC.get_attribute('id'),CAP_LIB.get_attribute('id')])\n",
    "                \n",
    "    # print(report)\n",
    "    # print('\\n')\n",
    "    # print('--------------------------------')\n",
    "    time.sleep(sleep*2)\n",
    "    \n",
    "    tables=[]\n",
    "    \n",
    "    for p in range(len(list_of_prods)):\n",
    "\n",
    "            # make query\n",
    "            if list_of_prods[p][0] == 'NC':\n",
    "                \n",
    "                query='categoria=%s&subcategoria=%s&aval=T' % (list_of_prods[p][0],list_of_prods[p][1])\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                query='categoriaP=%s&subcategoriaP=%s&aval=P' % (list_of_prods[p][0],list_of_prods[p][1])\n",
    "\n",
    "            # make url query\n",
    "            url_query = url_products.split('?')[0] + '?' + query + '&' + url_products.split('?')[1]\n",
    "\n",
    "            # retrieve id asociated tables\n",
    "            table_id = dict_tables[list_of_prods[p][0]][list_of_prods[p][1]]\n",
    "\n",
    "            # go to url product by group\n",
    "            time.sleep(sleep)\n",
    "        \n",
    "            browser.get(url_query)\n",
    "\n",
    "            # load page\n",
    "            time.sleep(sleep)\n",
    "            page_source = browser.page_source\n",
    "\n",
    "            # catch tables\n",
    "            if isinstance(table_id,str): # case one table\n",
    "\n",
    "                # catch title table\n",
    "                \n",
    "                #title_table = browser.find_element_by_xpath('//div/p[@class=\"titulo_tabla\"]').text \n",
    "                # cathc table\n",
    "                print(url_query)\n",
    "                time.sleep(sleep*2)\n",
    "                table = pd.read_html(page_source,attrs={'id':table_id}, header=2)[0][1:-1]\n",
    "\n",
    "                # store table\n",
    "                DBG[list_of_prods[p][0]][list_of_prods[p][1]] = {table_id:table}\n",
    "                # ---- in building ----\n",
    "\n",
    "            elif isinstance(table_id, list): # case multiple tables\n",
    "                \n",
    "                DBG[list_of_prods[p][0]][list_of_prods[p][1]] ={}\n",
    "\n",
    "                for i in range(len(table_id)):\n",
    "                    \n",
    "                    # fix bug\n",
    "                    if list_of_prods[p][1] == 'DC_P' and i == 3:\n",
    "                        # catch title specific table \n",
    "                        title_table = browser.find_elements_by_xpath('//div/p[@class=\"titulo_tabla\"]')[i].text\n",
    "                        \n",
    "                        # catch table software\n",
    "                        table = pd.read_html(page_source,attrs={'id':table_id[i]}, header=2)[1][1:-1]\n",
    "                        \n",
    "                        # store table\n",
    "                        DBG[list_of_prods[p][0]][list_of_prods[p][1]]['DC_DES_P_TABLE'] = table\n",
    "                        \n",
    "\n",
    "                    # catch title specific table \n",
    "                    title_table = browser.find_elements_by_xpath('//div/p[@class=\"titulo_tabla\"]')[i].text\n",
    "\n",
    "                    # catch table trasmedia\n",
    "                    table = pd.read_html(page_source,attrs={'id':table_id[i]}, header=2)[0][1:-1]\n",
    "\n",
    "                    # store table\n",
    "                    DBG[list_of_prods[p][0]][list_of_prods[p][1]][table_id[i]]=table\n",
    "                \n",
    "        \n",
    "                    # -----------\n",
    "    DB.append(DBG)\n",
    "    LP.append(list_of_prods)\n",
    "    LR.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "plain-sierra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NC_P', 'ART_IMP_P'],\n",
       " ['NC_P', 'ART_ELE_P'],\n",
       " ['NC_P', 'LIB_P'],\n",
       " ['NC_P', 'CAP_LIB_P'],\n",
       " ['NC_P', 'NOT_CIE_P'],\n",
       " ['NC_P', 'PAT_P'],\n",
       " ['NC_P', 'PRD_INV_ART_P'],\n",
       " ['NC_P', 'VAR_VEG_P'],\n",
       " ['NC_P', 'VAR_ANI_P'],\n",
       " ['NC_P', 'RAZ_PEC_P'],\n",
       " ['NC_P', 'TRA_FIL_P'],\n",
       " ['DTI_P', 'DIS_IND_P'],\n",
       " ['DTI_P', 'CIR_INT_P'],\n",
       " ['DTI_P', 'SOFT_P'],\n",
       " ['DTI_P', 'NUTRA_P'],\n",
       " ['DTI_P', 'COL_CIENT_P'],\n",
       " ['DTI_P', 'REG_CIENT_P'],\n",
       " ['DTI_P', 'PLT_PIL_P'],\n",
       " ['DTI_P', 'PRT_IND_P'],\n",
       " ['DTI_P', 'SEC_IND_P'],\n",
       " ['DTI_P', 'PROT_VIG_EPID_P'],\n",
       " ['DTI_P', 'EMP_BSE_TEC_P'],\n",
       " ['DTI_P', 'EMP_CRE_CUL_P'],\n",
       " ['DTI_P', 'INN_GES_EMP_P'],\n",
       " ['DTI_P', 'INN_PROC_P'],\n",
       " ['DTI_P', 'REG_NORM_REGL_LEG_P'],\n",
       " ['DTI_P', 'CONP_TEC_P'],\n",
       " ['DTI_P', 'REG_AAD_P'],\n",
       " ['DTI_P', 'SIG_DIS_P'],\n",
       " ['ASC_P', 'GEN_CONT_IMP_P'],\n",
       " ['ASC_P', 'EV_CIENT_P'],\n",
       " ['ASC_P', 'RED_P'],\n",
       " ['ASC_P', 'TALL_CRE_P'],\n",
       " ['ASC_P', 'EVE_ART_P'],\n",
       " ['ASC_P', 'DOC_TRAB_P'],\n",
       " ['ASC_P', 'SEC_GENE_P'],\n",
       " ['ASC_P', 'BOL_RES_INV_P'],\n",
       " ['ASC_P', 'CON_INF_TEC_P'],\n",
       " ['ASC_P', 'EDIC_P'],\n",
       " ['ASC_P', 'INF_TEC_P'],\n",
       " ['ASC_P', 'PASC_P'],\n",
       " ['ASC_P', 'DC_P'],\n",
       " ['FRH_P', 'TES_DOC_P'],\n",
       " ['FRH_P', 'TES_MAST_P'],\n",
       " ['FRH_P', 'TES_PREG_P'],\n",
       " ['FRH_P', 'PROY_INV_DES_P'],\n",
       " ['FRH_P', 'PROY_INV_CRE_P'],\n",
       " ['FRH_P', 'PROY_INV_DES_INN_P'],\n",
       " ['FRH_P', 'PROY_INV_RESP_SOC_P'],\n",
       " ['FRH_P', 'ASE_PRG_ACA_P'],\n",
       " ['FRH_P', 'ASE_CRE_CUR_P'],\n",
       " ['FRH_P', 'ASE_PRG_ONDAS_P'],\n",
       " ['NC', 'LIB'],\n",
       " ['NC', 'CAP_LIB']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "important-roots",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Info_group': 0  NaN  (Fecha de última actualización del aval  10 de junio de 2019)  \\\n",
       " 0  NaN  (Fecha de última actualización del aval  10 de junio de 2019)   \n",
       " 1  NaN                                                            NaN   \n",
       " 2  NaN                                                            NaN   \n",
       " 3  NaN                                                            NaN   \n",
       " 4  NaN                                                            NaN   \n",
       " 5  NaN                                                            NaN   \n",
       " 6  NaN                                                            NaN   \n",
       " \n",
       " 0      Nombre Grupo              Nombre Líder       Nombre área  \\\n",
       " 0               NaN                       NaN               NaN   \n",
       " 1               NaN                       NaN               NaN   \n",
       " 2  Micología Médica                       NaN               NaN   \n",
       " 3               NaN                       NaN               NaN   \n",
       " 4               NaN                       NaN  Medicina Clínica   \n",
       " 5               NaN  MARIA DEL PILAR  JIMENEZ               NaN   \n",
       " 6               NaN                       NaN               NaN   \n",
       " \n",
       " 0 Revisión de productos (Nuevo) Verificador de información  \n",
       " 0                           NaN                        NaN  \n",
       " 1                           NaN                        NaN  \n",
       " 2                           NaN                        NaN  \n",
       " 3                           NaN                        Ver  \n",
       " 4                           NaN                        NaN  \n",
       " 5                           NaN                        NaN  \n",
       " 6                 Ver productos                        NaN  ,\n",
       " 'Members':     Nro.                          Integrante Fecha Inicio/Vinculación  \\\n",
       " 0      1                 Naranjo Díaz Andrea            enero de 2019   \n",
       " 1      2                Estrada Ospina Mateo            abril de 2018   \n",
       " 2      3        Zuleta Gonzalez Maria Camila            abril de 2016   \n",
       " 3      4      Jiménez Alzate María Del Pilar             mayo de 2008   \n",
       " 4      5             Saavedra Porras Isabela            enero de 2017   \n",
       " 5      6         RINCON BARBOSA DUBAN ANDRES       septiembre de 2018   \n",
       " 6      7           Barrera Escobar Sebastian            abril de 2016   \n",
       " 7      8                  Chica López Nataly            abril de 2018   \n",
       " 8      9      Sanchez Cifuentes Erika Andrea            julio de 2018   \n",
       " 9     10                leal misas ana maria            enero de 2015   \n",
       " 10    11  Sepúlveda Rivera Jessica Alejandra            junio de 2016   \n",
       " 11    12      alvarez acevedo laura carolina            enero de 2016   \n",
       " 12    13             Rúa Giraldo Alvaro León            julio de 2005   \n",
       " 13    14        Gómez Londoño Luisa Fernanda             mayo de 2016   \n",
       " 14    15    Sterling Rodriguez Nelson Andres       septiembre de 2018   \n",
       " 15    16               Arango Arteaga Myrtha             mayo de 2005   \n",
       " 16    17  Jaramillo Pulgarín Sandra Catalina          febrero de 2015   \n",
       " 17    18          Sierra Henao Jaime Alberto          febrero de 2015   \n",
       " 18    19        Molina Colorado Diana Yuledi            enero de 2015   \n",
       " 19    20               Araque Marín Pedronel            enero de 2015   \n",
       " 20    21         McEwen Ochoa Juan Guillermo            julio de 2005   \n",
       " 21    22         Urán Jiménez Martha Eugenia            junio de 2016   \n",
       " \n",
       "     Nro. Horas Dedicación  Avalar integrante  Unnamed: 5  \n",
       " 0                      20                NaN         NaN  \n",
       " 1                      20                NaN         NaN  \n",
       " 2                      20                NaN         NaN  \n",
       " 3                      20                NaN         NaN  \n",
       " 4                      20                NaN         NaN  \n",
       " 5                      10                NaN         NaN  \n",
       " 6                      20                NaN         NaN  \n",
       " 7                      20                NaN         NaN  \n",
       " 8                      40                NaN         NaN  \n",
       " 9                      20                NaN         NaN  \n",
       " 10                     20                NaN         NaN  \n",
       " 11                     40                NaN         NaN  \n",
       " 12                     20                NaN         NaN  \n",
       " 13                     40                NaN         NaN  \n",
       " 14                     10                NaN         NaN  \n",
       " 15                     20                NaN         NaN  \n",
       " 16                     10                NaN         NaN  \n",
       " 17                     10                NaN         NaN  \n",
       " 18                     10                NaN         NaN  \n",
       " 19                     10                NaN         NaN  \n",
       " 20                      2                NaN         NaN  \n",
       " 21                     20                NaN         NaN  ,\n",
       " 'NC_P': {'ART_IMP_P': {'ART_P_TABLE':   Unnamed: 0  \\\n",
       "   1          1   \n",
       "   \n",
       "                                                                                                                                                                                            Título del artículo  \\\n",
       "   1  ASOCIACIÓN ENTRE LA INFESTACIÓN POR DEMODEX SPP., LA PRESENCIA DE ROSÁCEA Y LA SEVERIDAD CLÍNICA EN SUJETOS ADULTOS ATENDIDOS EN LOS SERVICIOS DE DERMATOLOGÍA Y MICOLOGÍA DE LA UNIVERSIDAD DE ANTIOQUIA   \n",
       "   \n",
       "     Año de presentación Mes de presentación Volumen revista Página inicial  \\\n",
       "   1                2018               Enero              22             63   \n",
       "   \n",
       "     Página final      ISSN Categoría Última actualización Revisar  \n",
       "   1           63  01239392     ART_B           2020-03-09     NaN  },\n",
       "  'ART_ELE_P': {'ART_E_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título del artículo, Año de presentación, Mes de presentación, Volumen, URL del artículo, DOI del artículo, ISSN, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'LIB_P': {'LIB_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título del artículo, ISBN, Nombre editorial, Año de presentación, Mes de presentación, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'CAP_LIB_P': {'CAP_LIB_P_TABLE':   Unnamed: 0 Título del capítulo del libro  \\\n",
       "   1          1              Inmunidad Innata   \n",
       "   \n",
       "                                                       Título del libro  \\\n",
       "   1  Fundamentos De Medicina Enfermedades Infecciosas Del Homo Sapiens   \n",
       "   \n",
       "     ISBN del libro Año de presentación Mes de presentación Categoría  \\\n",
       "   1  9789588843155                2015               Enero       NaN   \n",
       "   \n",
       "     Última actualización Revisar  \n",
       "   1           2017-05-11     NaN  },\n",
       "  'NOT_CIE_P': {'NOT_CIE_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título de la nota, Año de presentación, Mes de presentación, Página inicial, Página final, Revista, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'PAT_P': {'PAT_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título del artículo, Vía solicitud, Nro patente, Título, Titular, Fecha, País, Gaceta de publicación, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'PRD_INV_ART_P': {'PAAD_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título de la obra, Año de creación, Mes de creación, Naturaleza de la obra, Área-Especialización, Título del proyecto, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'VAR_VEG_P': {'VV_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre de la variedad, Año de presentación, Mes de presentación, Ciclo, Estado, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'VAR_ANI_P': {'VA_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Variedad animal, Acto Admin ICA, Año de presentación, Mes de presentación, Categoría, Última actualización, Revisar, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'RAZ_PEC_P': {'RAZ_PEC_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre de la raza, Año, Mes, País, Categoría, Última actualización, Revisar, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'TRA_FIL_P': {'TRA_FIL_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título del libro, ISBN, Editorial, Categoría, Lugar de publicación, Fecha de publicación, Revisar, Unnamed: 8]\n",
       "   Index: []}},\n",
       " 'DTI_P': {'DIS_IND_P': {'DI_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre del diseño, Número del registro, Título del registro, Nombre del titular, Fecha, País, Gaceta de publicación, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'CIR_INT_P': {'ECI_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre del diseño, Número del registro, Título del registro, Nombre del titular, Fecha, País, Gaceta de publicación, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'SOFT_P': {'SF_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre del diseño, Año, Radicado Informe, Tipo de registro, Nro. registro, Titular, Fecha, País obtención, Proyecto, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'NUTRA_P': {'NUTRA_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre del producto, Año obtención registro, Mes obtención registro, País obtención registro, Número de registro INVIMA, Título de registro, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'COL_CIENT_P': {'COL_CIENT_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre de la colección, Fecha creación, Lugar creación, Institución, Categoría, Tipo de información, Revisar, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'REG_CIENT_P': {'REG_CIENT_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre del nuevo registro científico, Año obtención, Mes obtención, País obtención, Base de datos, Url, Artículo de investigación donde ha sido publicado, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'PLT_PIL_P': {'PP_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre planta piloto, Número de registro, Nombre de registro, Nombre del titular, Fecha de obtención, País obtención, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'PRT_IND_P': {'PI_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre del diseño, Año de presentación, Mes de presentación, País, Institución, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'SEC_IND_P': {'SE_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Producto, Producto/Proceso comercializado, Año, Valor contrato, Contrato licenciamiento, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'PROT_VIG_EPID_P': {'PROT_VIG_EPID_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título del protocolo, Año, Mes, Ciudad, Nombre de institución emisora, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'EMP_BSE_TEC_P': {'EBT_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Tipo, Empresa, Año, NIT, Categoría, Última actualización, Revisar, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'EMP_CRE_CUL_P': {'ICC_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Empresa, Año, NIT, Categoría, Última actualización, Revisar, Unnamed: 7, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'INN_GES_EMP_P': {'IG_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre de la innovación, Año, Tamaño de la empresa, Nombre de la empresa, Categoría, Última actualización, Revisar, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'INN_PROC_P': {'IPP_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre de la innovación, Año, Nombre de la Institución, Categoría, Última actualización, Revisar, Unnamed: 7, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'REG_NORM_REGL_LEG_P': {'RNR_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Tipo producto, Entidad que le emitió, Título, Año, País, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'CONP_TEC_P': {'CONP_TEC_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título del concepto, Año solicitud, Mes solicitud, Ciudad, Institución solicitante, N&uacte;mero consecutivo del concepto, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'REG_AAD_P': {'AAAD_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre de la obra, Institución que tiene la licencia, Fecha de otorgación de la licencia, Ciudad, País, Número de registros de derechos de autor, Nombre del proyecto, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'SIG_DIS_P': {'SD_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Número de registro, Nombre del registro, Nombre del titular, Año de obtención, Mes, País, Condiciones de uso, Categoría, Última actualización, Revisar]\n",
       "   Index: []}},\n",
       " 'ASC_P': {'GEN_CONT_IMP_P': {'GC_I_P_TABLE_1': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Tipo de producto, Nombre revista, Título del artículo, Año de presentación, Volumen, Página inicial, Página final, ISSN, Medio divulgación-URL, DOI, Categoría, Última actualización, Revisar]\n",
       "   Index: [],\n",
       "   'GC_I_P_TABLE_5': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título del libro, ISBN, Editorial, Lugar de publicación, Categoría, Fecha de publicación, Revisar, Unnamed: 8]\n",
       "   Index: [],\n",
       "   'GC_I_P_TABLE_6': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título del libro, ISBN, Editorial, Lugar de publicación, Categoría, Fecha de publicación, Proyecto de investigación, Revisar]\n",
       "   Index: [],\n",
       "   'GC_I_P_TABLE_7': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título del libro, ISBN, Editorial, Lugar de publicación, Categoría, Fecha de publicación, Proyecto de investigación, Revisar]\n",
       "   Index: []},\n",
       "  'EV_CIENT_P': {'EC_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre, Fecha de inicio, Fecha de finalización, Participantes, Instituciones, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'RED_P': {'RC_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre, Fecha de inicio, Fecha de finalización, Lugar, Página web, Comunidades, Instituciones participantes, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'TALL_CRE_P': {'TALL_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Tipo de taller, Nombre del evento, Fecha de inicio, Ámbito, Distinción, Mecanismo de selección, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'EVE_ART_P': {'EVEN_ART_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Tipo de evento, Nombre del evento, Fecha de inicio, Participantes, Instituciones, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'DOC_TRAB_P': {'WP_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Documento, Año, DOI, Página web, Institución, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'SEC_GENE_P': {'SEC_GENE_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre de la secuencia, Año solicitud, Mes solicitud, Ciudad, Base de datos, Url, Institució certificadora, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'BOL_RES_INV_P': {'BOL_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Documento, Año, Institución que lo publica, Categoría, Última actualización, Revisar, Unnamed: 7, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'CON_INF_TEC_P': {'CON_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Tipo producto, Nombre, Año, contrato, Categoría, Última actualización, Revisar, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'EDIC_P': {'ERL_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Producto, Nombre Edición, Año, Categoría, Última actualización, Revisar, Unnamed: 7, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'INF_TEC_P': {'IFI_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre, Año, Proyecto, Categoría, Última actualización, Revisar, Unnamed: 7, Unnamed: 8]\n",
       "   Index: [],\n",
       "   'INF_TEC_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Tipo producto, Nombre, Año, contrato, Categoría, Última actualización, Revisar, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'PASC_P': {'PASC_FOR_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre, Autor/Coautores, Institución, Fecha inicio realización del proyecto, Fecha fin realización del proyecto, Medio de verificación, Licencia Creative Commons u Open Data Commons del contenido, Tipo de formato, Categoría, Revisar]\n",
       "   Index: [],\n",
       "   'PASC_TRA_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre, Autor/Coautores, Institución, Fecha inicio realización del proyecto, Fecha fin realización del proyecto, Medio de verificación, Licencia Creative Commons u Open Data Commons del contenido, Tipo de formato, Categoría, Revisar]\n",
       "   Index: [],\n",
       "   'PASC_GEN_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre, Autor/Coautores, Institución, Fecha inicio realización del proyecto, Fecha fin realización del proyecto, Medio de verificación, Licencia Creative Commons u Open Data Commons del contenido, Tipo de formato, Categoría, Revisar]\n",
       "   Index: [],\n",
       "   'PASC_CAD_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre, Autor/Coautores, Institución, Fecha inicio realización del proyecto, Fecha fin realización del proyecto, Medio de verificación, Licencia Creative Commons u Open Data Commons del contenido, Tipo de formato, Categoría, Revisar]\n",
       "   Index: []},\n",
       "  'DC_P': {'DC_CD_P_TABLE': Empty DataFrame\n",
       "   Columns: [Título del proyecto, Autor/Coautores, Institución, Lugar, Fecha realización del proyecto, Fecha fin realización del proyecto, Medio de verificación, Revisar, Unnamed: 8]\n",
       "   Index: [],\n",
       "   'DC_CON_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título del proyecto, Autor/Coautores, Institución, Lugar, Fecha inicio realización del proyecto, Fecha fin realización del proyecto, Categoría, Medio de verificación, Revisar]\n",
       "   Index: [],\n",
       "   'DC_TRA_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título del proyecto, Autor/Coautores, Institución, Lugar, Fecha realización del proyecto, Fecha fin realización del proyecto, Categoría, Medio de verificación, Revisar]\n",
       "   Index: [],\n",
       "   'DC_DES_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título del proyecto, Autor/Coautores, Institución, Lugar, Fecha realización del proyecto, Fecha fin realización del proyecto, Categoría, Medio de verificación, Revisar]\n",
       "   Index: []}},\n",
       " 'FRH_P': {'TES_DOC_P': {'TD_P_TABLE':   Unnamed: 0  \\\n",
       "   1          1   \n",
       "   \n",
       "                                                                                                               Título  \\\n",
       "   1  Relaciones filogenéticas entre aislamientos colombianos de histoplasma capsulatum de origen ambiental y clinico   \n",
       "   \n",
       "                             Autor               Institución  \\\n",
       "   1  Luisa Fernanda Gómez Londoño  UNIVERSIDAD DE ANTIOQUIA   \n",
       "   \n",
       "                            Director Fecha inicio Fecha fin Reconocimiento  \\\n",
       "   1  María Del Pilar Jiménez Alzate       2015-1    2019-8       Aprobada   \n",
       "   \n",
       "     Categoría Última actualización Revisar  \n",
       "   1       NaN           2019-09-03     NaN  },\n",
       "  'TES_MAST_P': {'TM_P_TABLE':   Unnamed: 0  \\\n",
       "   1          1   \n",
       "   2          2   \n",
       "   \n",
       "                                                                                                                               Título  \\\n",
       "   1                Búsqueda de Histoplasma capsulatum en abonos y enmiendas orgánicas y su correspondencia con aislamientos clínicos   \n",
       "   2  Caracterización y evaluación de la actividad antibacteriana de emulsiones de limoneno estabilizadas con nanopartículas de plata   \n",
       "   \n",
       "                             Autor               Institución  \\\n",
       "   1  Luisa Fernanda Gómez Londoño  UNIVERSIDAD DE ANTIOQUIA   \n",
       "   2        Julián Echeverry Chica  UNIVERSIDAD DE ANTIOQUIA   \n",
       "   \n",
       "                            Director Fecha inicio Fecha fin Reconocimiento  \\\n",
       "   1  María Del Pilar Jiménez Alzate       2012-7    2016-7       Aprobada   \n",
       "   2    Luisa Fernanda Gómez Londoño       2018-2   2020-10       Aprobada   \n",
       "   \n",
       "     Categoría Última actualización Revisar  \n",
       "   1       NaN           2021-04-23     NaN  \n",
       "   2       NaN           2021-04-09     NaN  },\n",
       "  'TES_PREG_P': {'TP_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Título, Autor, Institución, Director, Fecha inicio, Fecha fin, Reconocimiento, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'PROY_INV_DES_P': {'PID_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre, Inicio, Finalización, Instituciones, Categoría, Última actualización, Revisar, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'PROY_INV_CRE_P': {'INV_CRE_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre, Inicio, Finalización, Instituciones, Categoría, Última actualización, Revisar, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'PROY_INV_DES_INN_P': {'PF_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre, Inicio, Finalización, Instituciones, Categoría, Última actualización, Revisar, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'PROY_INV_RESP_SOC_P': {'PE_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Nombre, Inicio, Finalización, Instituciones, Categoría, Última actualización, Revisar, Unnamed: 8]\n",
       "   Index: []},\n",
       "  'ASE_PRG_ACA_P': {'APGA_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Tipo, Nombre del programa, Institución, Acto administrativo, Fecha, Categoría, Ultima actualización, Revisar]\n",
       "   Index: []},\n",
       "  'ASE_CRE_CUR_P': {'ACC_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Tipo, Nombre del curso, Programa académico, Institución, Acto administrativo, Fecha, Categoría, Última actualización, Revisar]\n",
       "   Index: []},\n",
       "  'ASE_PRG_ONDAS_P': {'APO_P_TABLE': Empty DataFrame\n",
       "   Columns: [Unnamed: 0, Integrante, Nombre de la asesoría, Institución, Categoría, Última actualización, Revisar, Unnamed: 7, Unnamed: 8]\n",
       "   Index: []}},\n",
       " 'NC': {'LIB': {'LIB_T_AVAL_TABLE':   Unnamed: 0 Título del artículo               ISBN  \\\n",
       "   1          1   Hongos Y Alergias  978-84-8086-249-3   \n",
       "   \n",
       "                   Nombre editorial Año de presentación Mes de presentación  \\\n",
       "   1  Asociacion Espanola Micologia                2010               Enero   \n",
       "   \n",
       "     Categoría Última actualización Revisar  \n",
       "   1       NaN           2017-05-11     NaN  },\n",
       "  'CAP_LIB': {'CAP_LIB_T_AVAL_TABLE':   Unnamed: 0 Título del capítulo del libro  \\\n",
       "   1          1         Micosis Superficiales   \n",
       "   \n",
       "                                                       Título del libro  \\\n",
       "   1  Fundamentos De Medicina Enfermedades Infecciosas Del Homo Sapiens   \n",
       "   \n",
       "     ISBN del libro Año de presentación Mes de presentación Categoría  \\\n",
       "   1  9789588843155                2015               Enero       NaN   \n",
       "   \n",
       "     Última actualización Revisar  \n",
       "   1           2017-05-11     NaN  }}}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "smooth-beverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GC_I_P_TABLE_1': Empty DataFrame\n",
       " Columns: [Unnamed: 0, Tipo de producto, Nombre revista, Título del artículo, Año de presentación, Volumen, Página inicial, Página final, ISSN, Medio divulgación-URL, DOI, Categoría, Última actualización, Revisar]\n",
       " Index: [],\n",
       " 'GC_I_P_TABLE_5': Empty DataFrame\n",
       " Columns: [Unnamed: 0, Título del libro, ISBN, Editorial, Lugar de publicación, Categoría, Fecha de publicación, Revisar, Unnamed: 8]\n",
       " Index: [],\n",
       " 'GC_I_P_TABLE_6': Empty DataFrame\n",
       " Columns: [Unnamed: 0, Título del libro, ISBN, Editorial, Lugar de publicación, Categoría, Fecha de publicación, Proyecto de investigación, Revisar]\n",
       " Index: [],\n",
       " 'GC_I_P_TABLE_7': Empty DataFrame\n",
       " Columns: [Unnamed: 0, Título del libro, ISBN, Editorial, Lugar de publicación, Categoría, Fecha de publicación, Proyecto de investigación, Revisar]\n",
       " Index: []}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB[0]['ASC_P']['GEN_CONT_IMP_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "worse-influence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DC_CD_P_TABLE': Empty DataFrame\n",
       " Columns: [Título del proyecto, Autor/Coautores, Institución, Lugar, Fecha realización del proyecto, Fecha fin realización del proyecto, Medio de verificación, Revisar, Unnamed: 8]\n",
       " Index: [],\n",
       " 'DC_CON_P_TABLE': Empty DataFrame\n",
       " Columns: [Unnamed: 0, Título del proyecto, Autor/Coautores, Institución, Lugar, Fecha inicio realización del proyecto, Fecha fin realización del proyecto, Categoría, Medio de verificación, Revisar]\n",
       " Index: [],\n",
       " 'DC_TRA_P_TABLE': Empty DataFrame\n",
       " Columns: [Unnamed: 0, Título del proyecto, Autor/Coautores, Institución, Lugar, Fecha realización del proyecto, Fecha fin realización del proyecto, Categoría, Medio de verificación, Revisar]\n",
       " Index: [],\n",
       " 'DC_DES_P_TABLE': Empty DataFrame\n",
       " Columns: [Unnamed: 0, Título del proyecto, Autor/Coautores, Institución, Lugar, Fecha realización del proyecto, Fecha fin realización del proyecto, Categoría, Medio de verificación, Revisar]\n",
       " Index: []}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB[0]['ASC_P']['DC_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "encouraging-russell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NC_P', 'ART_IMP_P'],\n",
       " ['NC_P', 'ART_ELE_P'],\n",
       " ['NC_P', 'LIB_P'],\n",
       " ['NC_P', 'CAP_LIB_P'],\n",
       " ['NC_P', 'NOT_CIE_P'],\n",
       " ['NC_P', 'PAT_P'],\n",
       " ['NC_P', 'PRD_INV_ART_P'],\n",
       " ['NC_P', 'VAR_VEG_P'],\n",
       " ['NC_P', 'VAR_ANI_P'],\n",
       " ['NC_P', 'RAZ_PEC_P'],\n",
       " ['NC_P', 'TRA_FIL_P'],\n",
       " ['DTI_P', 'DIS_IND_P'],\n",
       " ['DTI_P', 'CIR_INT_P'],\n",
       " ['DTI_P', 'SOFT_P'],\n",
       " ['DTI_P', 'NUTRA_P'],\n",
       " ['DTI_P', 'COL_CIENT_P'],\n",
       " ['DTI_P', 'REG_CIENT_P'],\n",
       " ['DTI_P', 'PLT_PIL_P'],\n",
       " ['DTI_P', 'PRT_IND_P'],\n",
       " ['DTI_P', 'SEC_IND_P'],\n",
       " ['DTI_P', 'PROT_VIG_EPID_P'],\n",
       " ['DTI_P', 'EMP_BSE_TEC_P'],\n",
       " ['DTI_P', 'EMP_CRE_CUL_P'],\n",
       " ['DTI_P', 'INN_GES_EMP_P'],\n",
       " ['DTI_P', 'INN_PROC_P'],\n",
       " ['DTI_P', 'REG_NORM_REGL_LEG_P'],\n",
       " ['DTI_P', 'CONP_TEC_P'],\n",
       " ['DTI_P', 'REG_AAD_P'],\n",
       " ['DTI_P', 'SIG_DIS_P'],\n",
       " ['ASC_P', 'GEN_CONT_IMP_P'],\n",
       " ['ASC_P', 'EV_CIENT_P'],\n",
       " ['ASC_P', 'RED_P'],\n",
       " ['ASC_P', 'TALL_CRE_P'],\n",
       " ['ASC_P', 'EVE_ART_P'],\n",
       " ['ASC_P', 'DOC_TRAB_P'],\n",
       " ['ASC_P', 'SEC_GENE_P'],\n",
       " ['ASC_P', 'BOL_RES_INV_P'],\n",
       " ['ASC_P', 'CON_INF_TEC_P'],\n",
       " ['ASC_P', 'EDIC_P'],\n",
       " ['ASC_P', 'INF_TEC_P'],\n",
       " ['ASC_P', 'PASC_P'],\n",
       " ['ASC_P', 'DC_P'],\n",
       " ['FRH_P', 'TES_DOC_P'],\n",
       " ['FRH_P', 'TES_MAST_P'],\n",
       " ['FRH_P', 'TES_PREG_P'],\n",
       " ['FRH_P', 'PROY_INV_DES_P'],\n",
       " ['FRH_P', 'PROY_INV_CRE_P'],\n",
       " ['FRH_P', 'PROY_INV_DES_INN_P'],\n",
       " ['FRH_P', 'PROY_INV_RESP_SOC_P'],\n",
       " ['FRH_P', 'ASE_PRG_ACA_P'],\n",
       " ['FRH_P', 'ASE_CRE_CUR_P'],\n",
       " ['FRH_P', 'ASE_PRG_ONDAS_P'],\n",
       " ['NC', 'LIB'],\n",
       " ['NC', 'CAP_LIB']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "productive-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo Conocimiento (2)\n",
      "NC_P\n",
      "\tArtículos publicados en revistas especializadas - Impresos (1)\n",
      "\tART_IMP_P\n",
      "\tArtículos publicados en revistas especializadas - Electrónicos (0)\n",
      "\tART_ELE_P\n",
      "\tLibros resultado de investigación (0)\n",
      "\tLIB_P\n",
      "\tCapítulos en Libro resultado de investigación (1)\n",
      "\tCAP_LIB_P\n",
      "\tNotas científicas (0)\n",
      "\tNOT_CIE_P\n",
      "\tPatentes (0)\n",
      "\tPAT_P\n",
      "\tObras o productos de investigación creación en Artes, Arquitectura y Diseño (0)\n",
      "\tPRD_INV_ART_P\n",
      "\tVariedad Vegetal (0)\n",
      "\tVAR_VEG_P\n",
      "\tNueva Raza Animal (0)\n",
      "\tVAR_ANI_P\n",
      "\tPoblaciones mejoradas de razas pecuarias (0)\n",
      "\tRAZ_PEC_P\n",
      "\tTraducciones Filológicas y Edición de Fuentes (0)\n",
      "\tTRA_FIL_P\n",
      "Desarrollo Tecnológico e Innovación (0)\n",
      "DTI_P\n",
      "\tDiseño industrial (0)\n",
      "\tDIS_IND_P\n",
      "\tCircuitos integrados (0)\n",
      "\tCIR_INT_P\n",
      "\tSoftware (0)\n",
      "\tSOFT_P\n",
      "\tProductos nutraceúticos (0)\n",
      "\tNUTRA_P\n",
      "\tColecciones científicas (0)\n",
      "\tCOL_CIENT_P\n",
      "\tNuevos registros científicos (0)\n",
      "\tREG_CIENT_P\n",
      "\tPlanta Piloto (0)\n",
      "\tPLT_PIL_P\n",
      "\tPrototipo Industrial (0)\n",
      "\tPRT_IND_P\n",
      "\tSecreto Industrial (0)\n",
      "\tSEC_IND_P\n",
      "\tProtocolos de vigilancia epidemiológica (0)\n",
      "\tPROT_VIG_EPID_P\n",
      "\tEmpresas de base tecnológica (0)\n",
      "\tEMP_BSE_TEC_P\n",
      "\tEmpresas creativas y culturales (0)\n",
      "\tEMP_CRE_CUL_P\n",
      "\tInnovaciones generadas en la gestión empresarial (0)\n",
      "\tINN_GES_EMP_P\n",
      "\tInnovaciones en procesos o procedimientos (0)\n",
      "\tINN_PROC_P\n",
      "\tRegulaciones, normas, reglamentos o legislaciones (0)\n",
      "\tREG_NORM_REGL_LEG_P\n",
      "\tConceptos técnicos (0)\n",
      "\tCONP_TEC_P\n",
      "\tRegistros de Acuerdos de licencia para la explotación de obras de AAD (0)\n",
      "\tREG_AAD_P\n",
      "\tSignos distintivos (0)\n",
      "\tSIG_DIS_P\n",
      "Apropiación social del conocimiento y Divulgación Pública de la Ciencia (1)\n",
      "ASC_P\n",
      "\tGeneración de contenido impreso (1)\n",
      "\tGEN_CONT_IMP_P\n",
      "\tEventos Científicos (0)\n",
      "\tEV_CIENT_P\n",
      "\tRed de conocimiento especializado (0)\n",
      "\tRED_P\n",
      "\tTalleres de creación (0)\n",
      "\tTALL_CRE_P\n",
      "\tEventos Artísticos (0)\n",
      "\tEVE_ART_P\n",
      "\tDocumento de trabajo (0)\n",
      "\tDOC_TRAB_P\n",
      "\tNuevas secuencias genéticas (0)\n",
      "\tSEC_GENE_P\n",
      "\tBoletín divulgativo de resultado de investigación (0)\n",
      "\tBOL_RES_INV_P\n",
      "\tConsultoría cientìfico tecnológica (0)\n",
      "\tCON_INF_TEC_P\n",
      "\tEdición (0)\n",
      "\tEDIC_P\n",
      "\tInformes (0)\n",
      "\tINF_TEC_P\n",
      "\tProcesos de apropiación social del conocimiento (PASC) (0)\n",
      "\tPASC_P\n",
      "\tProductos de divulgación pública de la ciencia (0)\n",
      "\tDC_P\n",
      "Formación del Recurso Humano (3)\n",
      "FRH_P\n",
      "\tDirecciones de tesis de doctorado (1)\n",
      "\tTES_DOC_P\n",
      "\tDirecciones de trabajo de grado de maestría (2)\n",
      "\tTES_MAST_P\n",
      "\tDirecciones de trabajos de pregrado (0)\n",
      "\tTES_PREG_P\n",
      "\tProyecto de investigación y desarrollo (0)\n",
      "\tPROY_INV_DES_P\n",
      "\tProyecto de investigación + creación (0)\n",
      "\tPROY_INV_CRE_P\n",
      "\tProyecto de investigación, desarrollo e innovación (ID+I) (0)\n",
      "\tPROY_INV_DES_INN_P\n",
      "\tProyecto de extensión y de responsabilidad social en CTeI (0)\n",
      "\tPROY_INV_RESP_SOC_P\n",
      "\tApoyo a la creación de programas académicos (0)\n",
      "\tASE_PRG_ACA_P\n",
      "\tApoyo a la creación de cursos (0)\n",
      "\tASE_CRE_CUR_P\n",
      "\tAcompañamiento y asesoría de línea temática del Programa Ondas (0)\n",
      "\tASE_PRG_ONDAS_P\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(LR[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fluid-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(LD)==len(LP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "provincial-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(df):\n",
    "    \n",
    "    info= {\n",
    "        'Nombre_Grupo' : df['Nombre Grupo'].dropna().iloc[0],\n",
    "\n",
    "        'Nombre_Lider' : df['Nombre Líder'].dropna().iloc[0],\n",
    "\n",
    "        'Nombre_Area'  : df['Nombre área'].dropna().iloc[0]\n",
    "    }\n",
    "    \n",
    "    dfi = pd.DataFrame(info, index=[0])\n",
    "  \n",
    "    \n",
    "    return dfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "informal-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBEH = {\n",
    "    \n",
    "    'INFO_GROUP': 'TABLE',\n",
    "    'MEMBERS':['Identificación Nacionalidad','Tiene afiliación con UdeA', 'Si no tiene afiliación UdeA diligencie el nombre de la Institución','Nro. Horas de dedicación semanales que avala el Coordinador de grupo'], # 2\n",
    "       \n",
    "    'NC_P': {'ART_IMP_P': {'ART_P_TABLE':['URL','DOI','Si no tiene URL o DOI agregue una evidencia en el repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'ART_ELE_P': {'ART_E_P_TABLE':['URL','DOI','Si no tiene URL o DOI agregue una evidencia en el repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'LIB_P':     {'LIB_P_TABLE':['Proyecto de investigación del cual se derivó el libro (Código-Título)','Financiador(es) del proyecto del cual se derivó el libro', 'Financiador(es) de la publicación','Autores','Citas recibidas (si tiene)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'CAP_LIB_P': {'CAP_LIB_P_TABLE':['Proyecto de investigación del cual se derivó el libro que contiene el capítulo (Código-Título)','Financiador del proyecto del cual se derivó el libro que contiene el capítulo','Financiador de la publicación','Autores','Citas recibidas (si tiene)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'NOT_CIE_P': {'NOT_CIE_P_TABLE':['URL','DOI','Si no tiene URL o DOI genere una evidencia en el repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'PAT_P':     {'PAT_P_TABLE':['Autores', 'Examen de fondo favorable','Examen preliminar internacional favorable','Adjunta opiniones escritas de la bUsqueda internacional','Contrato de explotación','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}, #  123 -1\n",
    "             'PRD_INV_ART_P': {'PAAD_P_TABLE':['Autores','Tiene certificado institucional de la obra','Tiene certificado de la entidad que convoca al evento en el que participa','Tiene certificado de la entidad que convoca al premio en el que obtiene','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}, # 1 2 3 -1\n",
    "             'VAR_VEG_P':     {'VV_P_TABLE':['Autores','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'VAR_ANI_P':     {'VA_P_TABLE':['Autores','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'RAZ_PEC_P':     {'RAZ_PEC_P_TABLE':['Autores','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'TRA_FIL_P': {'TRA_FIL_P_TABLE':['Proyecto de investigación del cual se derivó el libro (Código-Título)','Financiador(es) del proyecto del cual se derivó el libro','Financiador(es) de la publicación','Autores','Citas recibidas (si tiene)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}\n",
    "            },\n",
    "     'DTI_P': {'DIS_IND_P': {'DI_P_TABLE':['Autores','Contrato (si aplica)','Nombre comercial (si aplica)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'CIR_INT_P': {'ECI_P_TABLE':['Autores','Contrato (si aplica)','Nombre comercial (si aplica)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'SOFT_P': {'SF_P_TABLE':['Autores','Contrato (si aplica)','Nombre comercial (si aplica)','TRL','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'NUTRA_P': {'NUTRA_P_TABLE':['Autores','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']}, # add\n",
    "              'COL_CIENT_P': {'COL_CIENT_P_TABLE':['Autores','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo', '¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'REG_CIENT_P': {'REG_CIENT_P_TABLE':['Autores','Contrato licenciamiento (si aplica)','Agregue las evidencias verificadas al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'PLT_PIL_P': {'PP_P_TABLE':['Autores','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'PRT_IND_P': {'PI_P_TABLE':['Autores','Nombre comercial (si aplica)','TRL','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'SEC_IND_P': {'SE_P_TABLE':['Autores','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'PROT_VIG_EPID_P': {'PROT_VIG_EPID_P_TABLE':['Autores','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'EMP_BSE_TEC_P': {'EBT_P_TABLE':['Autores','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'EMP_CRE_CUL_P': {'ICC_P_TABLE':['Autores','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'INN_GES_EMP_P': {'IG_P_TABLE':['Autores','Contrato (si aplica)','Nombre comercial (si aplica)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'INN_PROC_P': {'IPP_P_TABLE':['Autores','Contrato (si aplica)','Nombre comercial (si aplica)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'REG_NORM_REGL_LEG_P': {'RNR_P_TABLE':['Autores','Contrato (si aplica)','Convenio (si aplica)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'CONP_TEC_P': {'CONP_TEC_P_TABLE':['Autores','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'REG_AAD_P': {'AAAD_P_TABLE':['Autores','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'SIG_DIS_P': {'SD_P_TABLE':['Autores','Contrato licenciamiento (si aplica)','Agregue las evidencias verificadas al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']}\n",
    "              },\n",
    "    'ASC_P': {'GEN_CONT_IMP_P': {'GC_I_P_TABLE_5':['Autores','Citas recibidas (si tiene)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'PASC_P': {'PASC_FOR_P_TABLE':['Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?'],\n",
    "               'PASC_TRA_P_TABLE':['Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?'],\n",
    "               'PASC_GEN_P_TABLE':['Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?'],\n",
    "               'PASC_CAD_P_TABLE':['Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'DC_P': {'DC_CD_P_TABLE':['Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?'],\n",
    "               'DC_CON_P_TABLE':['Medio de verificación','Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?'],\n",
    "               'DC_TRA_P_TABLE':['Medio de verificación','Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?'],\n",
    "               'DC_DES_P_TABLE':['Medio de verificación','Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}},\n",
    "    \n",
    "    'FRH_P': {'TES_DOC_P': {'TD_P_TABLE':['Número de cédula del graduado','¿La fecha fin coincide con la fecha de grado del estudiante?','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},  # 1 -1\n",
    "              'TES_MAST_P': {'TM_P_TABLE':['Número de cédula del graduado','¿La fecha fin coincide con la fecha de grado del estudiante?','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}, # 1 -1\n",
    "              'TES_PREG_P': {'TP_P_TABLE':['Número de cédula del graduado','¿La fecha fin coincide con la fecha de grado del estudiante?','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}, # 1 -1\n",
    "              'ASE_PRG_ACA_P': {'APGA_P_TABLE':['Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'ASE_CRE_CUR_P': {'ACC_P_TABLE':['Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'ASE_PRG_ONDAS_P': {'APO_P_TABLE':['Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}},\n",
    "    'NC' : {'LIB' : {'LIB_T_AVAL_TABLE': ['Proyecto de investigación del cual se derivó el libro (Código-Título)','Financiador(es) del proyecto del cual se derivó el libro', 'Financiador(es) de la publicación','Autores','Citas recibidas (si tiene)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}, \n",
    "            'CAP_LIB':{'CAP_LIB_T_AVAL_TABLE':['Proyecto de investigación del cual se derivó el libro que contiene el capítulo (Código-Título)','Financiador del proyecto del cual se derivó el libro que contiene el capítulo','Financiador de la publicación','Autores','Citas recibidas (si tiene)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "korean-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "                '1': 'C',\n",
    "                '2': 'D',\n",
    "                '3': 'E',\n",
    "                '4': 'F',\n",
    "                '5': 'G',\n",
    "                '6': 'H',\n",
    "                '7': 'I',\n",
    "                '8': 'J',\n",
    "                '9': 'K',\n",
    "                '10': 'L',\n",
    "                '11': 'M',\n",
    "                '12': 'N',\n",
    "                '13': 'O',\n",
    "                '14': 'P',\n",
    "                '15': 'Q',\n",
    "                '16': 'R',\n",
    "                '17': 'S',\n",
    "                '18': 'T',\n",
    "                '19': 'U',\n",
    "                '20': 'V'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "illegal-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    'remove innecesari collums'\n",
    "    c=[x for x in df.columns if x.find('Unnamed:') == -1 and  x.find('Revisar') == -1]\n",
    "    dfc=df[c]\n",
    "    return dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "legendary-convert",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-92-3f5250ce3284>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-92-3f5250ce3284>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1. Presentación:\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1. Presentación: \n",
    "2. Datos de contacto: comprende información relativa al Grupo y al Centro, Instituto o Corporación que verifica la información. Diligenciar fila 8.\n",
    "3. Integrantes: comprende la información relacionada a los integrantes de los grupos de investigación que se debe verificar y completar.\n",
    "4. ART y N: \n",
    "5. LIB Y LIB_FOR: \n",
    "6. CAP:\n",
    "7. Patente y variedades: \n",
    "8. AAD:   \n",
    "9. Tecnológico: \n",
    "10. Empresarial: \n",
    "11. ASC y Divulgación Pública de la Ciencia: \n",
    "12. Formación y programas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "detected-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(df, sheet_name, start_row, writer,eh, veh =None):\n",
    "    'format headers'\n",
    "    \n",
    "    df.to_excel(writer,sheet_name, startrow = start_row+1, startcol=2,index = False)\n",
    "\n",
    "    # Get the xlsxwriter workbook and worksheet objects.\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    \n",
    "    #form merge cells\n",
    "    start,end = 1,df.shape[1]\n",
    "\n",
    "    m_range = d.get(str(start)) + str(start_row + 1) + ':' + d.get(str(end)) + str(start_row +1)\n",
    "\n",
    "    worksheet.merge_range(m_range, 'Información suministrada por la Vicerrectoría de Investigación', merge_format)\n",
    "    \n",
    "    # for merge cells\n",
    "    _m_range = d.get(str(end+1)) + str(start_row +1) + ':' +  d.get(str(end+len(eh))) + str(start_row +1)\n",
    "    \n",
    "    worksheet.merge_range(_m_range, 'Validación del Centro, Instituto o Corporación', merge_format)\n",
    "        \n",
    "    worksheet.set_row_pixels(start_row+1, 120)\n",
    "    #worksheet.set_column('C:C',30,general)\n",
    "    \n",
    "    # SET COLUMS BY SHEET\n",
    "    \n",
    " \n",
    "    if sheet_name == '3.Integrantes grupo':\n",
    "        \n",
    "        worksheet.set_column('C:C', 10,general)\n",
    "        worksheet.set_column('D:D', 30,general)\n",
    "        worksheet.set_column('E:G', 15,general)\n",
    "        \n",
    "    elif sheet_name== 'NC_P':\n",
    "        \n",
    "        worksheet.set_column('C:C', 30,general)\n",
    "        worksheet.set_column('D:K', 20,general)\n",
    "    elif sheet_name == 'FRH_P':\n",
    "        \n",
    "        worksheet.set_column('C:C', 30,general)\n",
    "        worksheet.set_column('D:K', 20,general)\n",
    "    else:\n",
    "        worksheet.set_column('C:C', 30,general)\n",
    "        worksheet.set_column('D:K', 20,general)\n",
    "    \n",
    "    worksheet.set_column('A:A', 15)\n",
    "    worksheet.set_column('B:B', 5)\n",
    "        \n",
    "    worksheet.write(start_row+1, 0, 'VoBo de VRI', merge_format)\n",
    "    # Add a header format.\n",
    "    \n",
    "    fmt_header = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'align': 'center',    \n",
    "        'text_wrap': True,\n",
    "        'valign': 'vcenter',\n",
    "        'fg_color': '#33A584',\n",
    "        'font_color': '#FFFFFF',\n",
    "        'border': 1})\n",
    "    \n",
    "    \n",
    "    # Write the column headers with the defined format.\n",
    "    for col_num, value in enumerate(df.columns.values):\n",
    "        worksheet.write(start_row+1, col_num + 2, value, fmt_header)\n",
    "        \n",
    "    # write extra headers\n",
    "    for col_num, value in enumerate(eh):\n",
    "        worksheet.write(start_row+1, col_num + df.shape[1] + 2, value, fmt_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "interim-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_info(df, writer, sheet_name):\n",
    "    \n",
    "    '''format worksheet'''\n",
    "    \n",
    "    workbook=writer.book\n",
    "    \n",
    "    normal=workbook.add_format({'font_size':12,'text_wrap':True})\n",
    "    \n",
    "    merge_format = workbook.add_format({\n",
    "    'bold': 1,\n",
    "    'border':1,\n",
    "    'text_wrap': True,    \n",
    "    'align': 'center',\n",
    "    'valign': 'vcenter',\n",
    "    'font_color': 'black'})\n",
    "    \n",
    "    fmt_header = workbook.add_format({\n",
    "        'align': 'center',    \n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#33A584',\n",
    "        'font_color': '#FFFFFF',\n",
    "        'border': 1})\n",
    "    \n",
    "    # write df\n",
    "    start_row = 6\n",
    "    start_col = 3\n",
    "    \n",
    "    df.to_excel(writer, sheet_name, startrow =start_row, startcol=start_col,index = False)\n",
    "\n",
    "    # get worksheet object\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    \n",
    "    for col_num, value in enumerate(df.columns.values):\n",
    "        worksheet.write(start_row, col_num + 3, value, fmt_header)\n",
    "    \n",
    "    #Prepare image insertion: See → https://xlsxwriter.readthedocs.io/example_images.html\n",
    "    worksheet.set_column('A:A', 15)\n",
    "    worksheet.set_column('B:B', 15)\n",
    "    worksheet.insert_image('A1', 'img/udea.jpeg')\n",
    "    \n",
    "    # title 1 UNIVERSIDAD DE ANTIOQUIA\n",
    "    title = workbook.add_format({'font_size':16,'center_across':True})\n",
    "\n",
    "    # title 2 Vicerrectoria de Investigación\n",
    "    title2 = workbook.add_format({'font_size':16,'center_across':True})\n",
    "   \n",
    "    # sub title 2 datos identificacion contacto\n",
    "    title3 = workbook.add_format({'font_size':12,'center_across':True})\n",
    "    \n",
    "    # merge d1:f1\n",
    "    worksheet.merge_range('D1:F1', 'UNIVERSIDAD DE ANTIOQUIA', title)\n",
    "        \n",
    "    # merge d2:f2\n",
    "    worksheet.merge_range('D2:F2', ' Vicerrectoria de Investigación', title2)\n",
    "    \n",
    "    # merge d3:f3\n",
    "    worksheet.merge_range('D3:F3', ' Datos de identificación y contacto', title3)\n",
    "    \n",
    "    # D5: F5\n",
    "    worksheet.merge_range('D5:E5','Número inscripcion a la convocatoria:',merge_format)\n",
    "    worksheet.write('F5','#',merge_format)\n",
    "    \n",
    "    # d6:f6\n",
    "    worksheet.merge_range('D6:F6','Identificación del Grupo',merge_format)\n",
    "        \n",
    "    # d9:f9\n",
    "    worksheet.merge_range('D10:F10','Identificación del Centro de Investigación',merge_format)\n",
    "    # write \n",
    "    a='Nombre del Centro, Instituto o Corporación'\n",
    "    worksheet.write('D11',a, fmt_header)\n",
    "    worksheet.set_column('D11:D11',30, fmt_header)\n",
    "    \n",
    "    b='Nombre completo del Jefe de Centro, Instituto o Corporación'\n",
    "    worksheet.write('E11',b, fmt_header) \n",
    "    worksheet.set_column('E11:E11',30, fmt_header)\n",
    "    \n",
    "    c='Email'\n",
    "    worksheet.write('F11',c, fmt_header) \n",
    "    worksheet.set_column('F11:F11',30, fmt_header)\n",
    "    \n",
    "    # d13:f13\n",
    "    worksheet.merge_range('D13:F13','Identificación de quien diligencia el formato',merge_format)\n",
    "    a='Nombre completo del encargado de diligenciar el formato'\n",
    "    worksheet.write('D14',a, fmt_header)\n",
    "    worksheet.set_column('D14:D14',30, normal)\n",
    "    \n",
    "    b='Email'\n",
    "    worksheet.write('E14',b, fmt_header) \n",
    "    worksheet.set_column('E14:E14',30, normal)\n",
    "    \n",
    "    c='Teléfono de contacto'\n",
    "    worksheet.write('F14',c, fmt_header) \n",
    "    worksheet.set_column('F14:F14',30, normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "sudden-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE GROUP IMPLEMENTATION\n",
    "idxx = 34\n",
    "\n",
    "# DATA\n",
    "DBG = DB[0]\n",
    "\n",
    "### excel name\n",
    "name = 'AA_Plantilla_Formato de verificación de información_GrupLAC_894-2021_%s'\n",
    "\n",
    "# initialize object= output excel file\n",
    "writer = pd.ExcelWriter(name % dfg.loc[idxx,'COL Grupo']+'.xlsx', engine='xlsxwriter')\n",
    "\n",
    "#Global variables\n",
    "abstract_text='VERIFICACIÓN DE INFORMACIÓN PARA OTORGAR AVAL A LOS GRUPOS DE INVESTIGACIÓN  E INVESTIGADORES PARA SU PARTICIPACIÓN EN LA CONVOCATORIA 894 DE 2021 DE MINCIENCIAS'\n",
    "instructions='''Los grupos de investigación e investigadores de la Universidad de Antioquia que deseen participar en la Convocatoria Nacional para el reconocimiento y medición de grupos de investigación, desarrollo tecnológico o de innovación y para el reconocimiento de investigadores del Sistema Nacional de Ciencia, Tecnología e Innovación - SNCTI, 894 de 2021, deben presentar la información actualizada en las plataformas CvLAC y GrupLAC validada por el Centro de Investigación en el presente formato, y respaldada en el repositorio digital de evidencias dispuesto para este fin, para la obtención del aval institucional por parte de la Vicerrectoría de Investigación. \n",
    "\n",
    "La información a validar corresponde a los años 2019-2020 y aquella que entra en la ventana de observación y debe ser modificada según el Modelo de medición de grupos. La validación comprende:\n",
    "\n",
    "1. Verificación de la vinculación de los integrantes a la Universidad de Antioquia y al grupo de investigación.  Diligenciar los campos solicitados. \n",
    "\n",
    "2. Verificación de la producción de GNC, DTeI, ASC y FRH, en los campos habilitados en cada hoja de este formato. Las evidencias requeridas para los productos deben ser anexadas al repositorio digital asignado al grupo y se deben enlazar a cada producto.  \n",
    "\n",
    "Este documento debe ser diligenciado en línea.\n",
    "\n",
    "De antemano, la Vicerrectoría de Investigación agradece su participación en este ejercicio, que resulta de vital importancia para llevar a buen término la Convocatoria de Reconocimiento y Medición de Grupos de Investigación\n",
    "'''\n",
    "#Final part of the first sheet\n",
    "datos=clean_df(pd.read_excel('https://github.com/restrepo/InstituLAC/raw/main/data/template_data.xlsx'))\n",
    "\n",
    "#Capture xlsxwriter object \n",
    "# IMPORTANT → workbook is the same object used in the official document at https://xlsxwriter.readthedocs.io\n",
    "workbook=writer.book\n",
    "#***************\n",
    "#Styles as explained in https://xlsxwriter.readthedocs.io\n",
    "general=workbook.add_format({'text_wrap':True})\n",
    "title=workbook.add_format({'font_size':28,'center_across':True})\n",
    "subtitle=workbook.add_format({'font_size':24,'center_across':True})\n",
    "abstract=workbook.add_format({'font_size':20,'center_across':True,'text_wrap':True})\n",
    "normal=workbook.add_format({'font_size':12,'text_wrap':True})\n",
    "\n",
    "merge_format = workbook.add_format({\n",
    "    'bold': 1,\n",
    "    'border':1,\n",
    "    'text_wrap': True,    \n",
    "    'align': 'center',\n",
    "    'valign': 'vcenter',\n",
    "    'font_color': 'blue'})\n",
    "\n",
    "fmt_header = workbook.add_format({\n",
    "    'bold': True,\n",
    "    'align': 'center',    \n",
    "    'text_wrap': True,\n",
    "    'valign': 'top',\n",
    "    'fg_color': '#33A584',\n",
    "    'font_color': '#FFFFFF',\n",
    "    'border': 1})\n",
    "#***************\n",
    "#Creates the first work-sheet\n",
    "#IMPORTANT → worksheet is the same object  used in the official document at https://xlsxwriter.readthedocs.io\n",
    "worksheet=workbook.add_worksheet(\"1.Presentación\")\n",
    "#Prepare image insertion: See → https://xlsxwriter.readthedocs.io/example_images.html\n",
    "worksheet.set_column('A:A', 15)\n",
    "worksheet.set_column('B:B', 15)\n",
    "worksheet.insert_image('A1', 'img/udea.jpeg')\n",
    "#Prepare text insertion: See  → https://xlsxwriter.readthedocs.io/example_images.html\n",
    "worksheet.set_column('C:C', 140,general)\n",
    "worksheet.set_row_pixels(0, 60)\n",
    "#Texts\n",
    "worksheet.write('C1', 'UNIVERSIDAD DE ANTIOQUIA',title)\n",
    "worksheet.set_row_pixels(2, 60)\n",
    "worksheet.write('C3', 'VICERRECTORÍA DE INVESTIGACIÓN',subtitle)\n",
    "worksheet.set_row_pixels(5, 100)\n",
    "worksheet.write('C6', abstract_text,abstract)\n",
    "worksheet.set_row_pixels(8, 40)\n",
    "worksheet.write('C9','PRESENTACIÓN DEL EJERCICIO',\n",
    "                workbook.add_format({'font_size':18,'center_across':True}) )\n",
    "worksheet.set_row_pixels(10, 320)\n",
    "worksheet.write('C11',instructions,normal )\n",
    "#*** ADD PANDAS DATAFRAME IN SPECIFIC POSITION ****\n",
    "#Add a data Frame in some specific position. See → https://stackoverflow.com/a/43510881/2268280\n",
    "#                                       See also → https://xlsxwriter.readthedocs.io/working_with_pandas.html\n",
    "writer.sheets[\"1.Presentación\"]=worksheet\n",
    "datos.to_excel(writer,sheet_name=\"1.Presentación\",startrow=12,startcol=2,index=False)\n",
    "#**************************************************\n",
    "#Fix columns heights for long text\n",
    "worksheet.set_row_pixels(17, 40)\n",
    "worksheet.set_row_pixels(18, 40)\n",
    "worksheet.set_row_pixels(19, 40)\n",
    "worksheet.set_row_pixels(20, 40)\n",
    "worksheet.set_row_pixels(22, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "educated-korean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Add extra headers\\nworksheet2.write(1, 0, 'VoBo de VRI', merge_format)\\n#New columns\\nextra_url='Si no tiene URL o DOI agregue una evidencia en el repositorio digital y genere un hipervínculo en este campo'\\ncols=['DOI',extra_url,'¿El producto cumple con los requisitos para ser avalado?']\\nfor col , value in enumerate(cols):\\n    worksheet2.write(1, col+2+table.columns.size, value, fmt_header)\\nworksheet2.set_column('L:L',20)\\nworksheet2.set_column('M:M',20)\\n#Creates a set of cells with a drop-down menu Sí/No. See → https://xlsxwriter.readthedocs.io/working_with_data_validation.html\\nworksheet2.data_validation('M3:M{}'.format(table.shape[0]+2), {'validate': 'list',\\n                                  'source': ['Sí', 'No']})\\n\\nworkbook.close()\\n\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Add extra headers\n",
    "worksheet2.write(1, 0, 'VoBo de VRI', merge_format)\n",
    "#New columns\n",
    "extra_url='Si no tiene URL o DOI agregue una evidencia en el repositorio digital y genere un hipervínculo en este campo'\n",
    "cols=['DOI',extra_url,'¿El producto cumple con los requisitos para ser avalado?']\n",
    "for col , value in enumerate(cols):\n",
    "    worksheet2.write(1, col+2+table.columns.size, value, fmt_header)\n",
    "worksheet2.set_column('L:L',20)\n",
    "worksheet2.set_column('M:M',20)\n",
    "#Creates a set of cells with a drop-down menu Sí/No. See → https://xlsxwriter.readthedocs.io/working_with_data_validation.html\n",
    "worksheet2.data_validation('M3:M{}'.format(table.shape[0]+2), {'validate': 'list',\n",
    "                                  'source': ['Sí', 'No']})\n",
    "\n",
    "workbook.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "purple-milan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['INFO_GROUP', 'MEMBERS', 'NC_P', 'DTI_P', 'ASC_P', 'FRH_P', 'NC'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DBEH.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "planned-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO GROUP\n",
    "df=get_info(DBG['Info_group'])\n",
    "format_info(df, writer, '2.Datos de contacto')\n",
    "\n",
    "# WORKSHEET 1\n",
    "df = clean_df(DBG['Members']) \n",
    "eh = DBEH['MEMBERS']\n",
    "format_df(df, '3.Integrantes grupo', 1, writer, eh, veh=0) #### veh = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "compact-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NC_P ### \n",
    "\n",
    "#------- w4 -------\n",
    "# 4.ART y N\n",
    "\n",
    "var_w4 = 0\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['ART_IMP_P']['ART_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc+1)\n",
    "    \n",
    "    eh=DBEH['NC_P']['ART_IMP_P']['ART_P_TABLE']\n",
    "\n",
    "    format_df(df, '4.ART y N',  var_w4, writer,eh)\n",
    "        \n",
    "    var_w4 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['ART_ELE_P']['ART_E_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['ART_ELE_P']['ART_E_P_TABLE']\n",
    "\n",
    "    format_df(df, '4.ART y N', var_w4, writer,eh)\n",
    "        \n",
    "    var_w4 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['NOT_CIE_P']['NOT_CIE_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['NOT_CIE_P']['NOT_CIE_P_TABLE']\n",
    "\n",
    "    format_df(df, '4.ART y N', var_w4, writer,eh)\n",
    "        \n",
    "    var_w4 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "# -------------- w4 -------------------------\n",
    "\n",
    "#------------ ---w5------------\n",
    "# 5.LIB y LIB_FOR\n",
    "var_w5 = 0\n",
    "\n",
    "# libros por pertenencia\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['LIB_P']['LIB_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['LIB_P']['LIB_P_TABLE']\n",
    "\n",
    "    format_df(df, '5.LIB y LIB_FOR',  var_w5, writer,eh)\n",
    "        \n",
    "    var_w5 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# libros avalados con revisión\n",
    "try:\n",
    "    df=clean_df(DBG['NC']['LIB']['LIB_T_AVAL_TABLE'])  ### ,veh = 2\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='FRH_P',startrow = var_rh)\n",
    "    \n",
    "    eh=DBEH['NC']['LIB']['LIB_T_AVAL_TABLE']\n",
    "\n",
    "    format_df(df, '5.LIB y LIB_FOR', var_w5 , writer, eh)\n",
    "        \n",
    "    var_w5  += df.shape[0] + 3\n",
    "\n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# libros formacion\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['GEN_CONT_IMP_P']['GC_I_P_TABLE_5']) # lib form\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['GEN_CONT_IMP_P']['GC_I_P_TABLE_5']\n",
    "\n",
    "    format_df(df, '5.LIB y LIB_FOR',  var_w5 , writer,eh)\n",
    "        \n",
    "    var_w5 += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass  \n",
    "# --------------------w5--------------\n",
    "\n",
    "#--------------------w6---------------\n",
    "#6.CAP\n",
    "\n",
    "# cap pertenencia\n",
    "\n",
    "var_w6 = 0\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['CAP_LIB_P']['CAP_LIB_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['CAP_LIB_P']['CAP_LIB_P_TABLE']\n",
    "\n",
    "    format_df(df, '6.CAP',var_w6, writer,eh)\n",
    "        \n",
    "    var_w6 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# caps avalados con revision\n",
    "try:\n",
    "    df = clean_df(DBG['NC']['CAP_LIB']['CAP_LIB_T_AVAL_TABLE'])  ### ,veh = 2\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='FRH_P',startrow = var_rh)\n",
    "    \n",
    "    eh = DBEH['NC']['CAP_LIB']['CAP_LIB_T_AVAL_TABLE']\n",
    "\n",
    "    format_df(df, '6.CAP', var_w6, writer, eh)\n",
    "        \n",
    "    var_w6 += df.shape[0] + 3\n",
    "\n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# traduccion filologica\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['TRA_FIL_P']['TRA_FIL_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['TRA_FIL_P']['TRA_FIL_P_TABLE']\n",
    "\n",
    "    format_df(df, '6.CAP', var_w6, writer,eh)\n",
    "        \n",
    "    var_w6 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "#-------------------w6------------------\n",
    "\n",
    "#------------w7-------------------------\n",
    "#7.Patente_Variedades\n",
    "var_w7 = 0\n",
    "\n",
    "# patentes\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['PAT_P']['PAT_P_TABLE']) ###### veh=1\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['PAT_P']['PAT_P_TABLE']\n",
    "\n",
    "    format_df(df, '7.Patente_Variedades', var_w7, writer,eh, veh=1)\n",
    "        \n",
    "    var_w7 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# productos investigacion creacion\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['PRD_INV_ART_P']['PAAD_P_TABLE']) ###### veh = 1\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['PRD_INV_ART_P']['PAAD_P_TABLE']\n",
    "\n",
    "    format_df(df, '7.Patente_Variedades', var_w7, writer,eh, veh=1)\n",
    "        \n",
    "    var_w7 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# variedad vegetal\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['VAR_VEG_P']['VV_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['VAR_VEG_P']['VV_P_TABLE']\n",
    "\n",
    "    format_df(df, '7.Patente_Variedades', var_w7, writer,eh)\n",
    "        \n",
    "    var_w7 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Variedad Animal\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['VAR_ANI_P']['VA_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['VAR_ANI_P']['VA_P_TABLE']\n",
    "\n",
    "    format_df(df, '7.Patente_Variedades', var_w7, writer,eh)\n",
    "        \n",
    "    var_w7 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# razas pecuarias mejoradas\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['RAZ_PEC_P']['RAZ_PEC_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['RAZ_PEC_P']['RAZ_PEC_P_TABLE']\n",
    "\n",
    "    format_df(df, '7.Patente_Variedades', var_w7, writer,eh)\n",
    "        \n",
    "    var_w7 += df.shape[0] + 3\n",
    "\n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "# ---------------w7---------------------\n",
    "\n",
    "#---------------w8-------------------\n",
    "var_w8 = 0\n",
    "\n",
    "# registros de acuerdo licencias expl obras AAD\n",
    "try:\n",
    "\n",
    "    df=clean_df(DBG['DTI_P']['REG_AAD_P']['AAAD_P_TABLE'])\n",
    "    \n",
    "    eh=DBEH['DTI_P']['REG_AAD_P']['AAAD_P_TABLE']\n",
    "\n",
    "    format_df(df, '8.AAD', var_w8, writer,eh)\n",
    "        \n",
    "    var_w8 += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "#-------------W8---------------------\n",
    "\n",
    "#-------------W9----------------\n",
    "\n",
    "# 9.Tecnológico\n",
    "#### DTI_P\n",
    "\n",
    "var_w9 = 0\n",
    "\n",
    "# diseño industrial\n",
    "try:\n",
    "\n",
    "    df=clean_df(DBG['DTI_P']['DIS_IND_P']['DI_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['DIS_IND_P']['DI_P_TABLE']\n",
    "\n",
    "    format_df(df, '9.Tecnológico', var_w9, writer, eh)\n",
    "        \n",
    "    var_w9 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "#circuitos integrados\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['CIR_INT_P']['ECI_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['CIR_INT_P']['ECI_P_TABLE']\n",
    "\n",
    "    format_df(df, '9.Tecnológico', var_w9, writer,eh)\n",
    "        \n",
    "    var_w9 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# colecciones\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['COL_CIENT_P']['COL_CIENT_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['COL_CIENT_P']['COL_CIENT_P_TABLE']\n",
    "\n",
    "    format_df(df, '9.Tecnológico', var_w9, writer,eh)\n",
    "        \n",
    "    var_w9 += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# software \n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['SOFT_P']['SF_P_TABLE'])\n",
    "    \n",
    "    eh=DBEH['DTI_P']['SOFT_P']['SF_P_TABLE']\n",
    "\n",
    "    format_df(df, '9.Tecnológico', var_w9, writer,eh)\n",
    "        \n",
    "    var_w9 += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# secreto industrial\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['SEC_IND_P']['SE_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['SEC_IND_P']['SE_P_TABLE']\n",
    "\n",
    "    format_df(df, '9.Tecnológico', var_w9, writer,eh)\n",
    "        \n",
    "    var_w9 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# prototipo insdustrial\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['PRT_IND_P']['PI_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['PRT_IND_P']['PI_P_TABLE']\n",
    "\n",
    "    format_df(df, '9.Tecnológico',  var_w9, writer,eh)\n",
    "        \n",
    "    var_w9 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Registro distintivo\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['SIG_DIS_P']['SD_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['SIG_DIS_P']['SD_P_TABLE']\n",
    "\n",
    "    format_df(df, '9.Tecnológico', var_w9, writer,eh)\n",
    "        \n",
    "    var_w9 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# prod nutracetico\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['NUTRA_P']['NUTRA_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['NUTRA_P']['NUTRA_P_TABLE']\n",
    "\n",
    "    format_df(df, '9.Tecnológico', var_w9, writer,eh)\n",
    "        \n",
    "    var_w9 += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# registro cienti\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['REG_CIENT_P']['REG_CIENT_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['REG_CIENT_P']['REG_CIENT_P_TABLE']\n",
    "\n",
    "    format_df(df, '9.Tecnológico',var_w9 , writer,eh)\n",
    "        \n",
    "    var_w9 += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# planta piloto\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['PLT_PIL_P']['PP_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['PLT_PIL_P']['PP_P_TABLE']\n",
    "\n",
    "    format_df(df, '9.Tecnológico', var_w9, writer,eh)\n",
    "        \n",
    "    var_w9 += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# prototipo vigilancia epidemologica\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['PROT_VIG_EPID_P']['PROT_VIG_EPID_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['PROT_VIG_EPID_P']['PROT_VIG_EPID_P_TABLE']\n",
    "\n",
    "    format_df(df, '9.Tecnológico',var_w9, writer,eh)\n",
    "        \n",
    "    var_w9 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "#---------------------w9----------------\n",
    "\n",
    "#---------------------w10----------------\n",
    "# 10.Empresarial\n",
    "var_w10 = 0\n",
    "\n",
    "# innovación gestion empresarial\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['INN_GES_EMP_P']['IG_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['INN_GES_EMP_P']['IG_P_TABLE']\n",
    "\n",
    "    format_df(df, '10.Empresarial', var_w10, writer,eh)\n",
    "        \n",
    "    var_w10 += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "# innovacion procesos y procedimiento\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['INN_PROC_P']['IPP_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['INN_PROC_P']['IPP_P_TABLE']\n",
    "\n",
    "    format_df(df, '10.Empresarial', var_w10, writer,eh)\n",
    "        \n",
    "    var_w10 += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# regulaciones normas reglamentos legislaciones\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['REG_NORM_REGL_LEG_P']['RNR_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['REG_NORM_REGL_LEG_P']['RNR_P_TABLE']\n",
    "\n",
    "    format_df(df, '10.Empresarial', var_w10, writer,eh)\n",
    "        \n",
    "    var_w10 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# conceptos tecnicos\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['CONP_TEC_P']['CONP_TEC_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['CONP_TEC_P']['CONP_TEC_P_TABLE']\n",
    "\n",
    "    format_df(df, '10.Empresarial', var_w10, writer,eh)\n",
    "        \n",
    "    var_w10 += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# empresa base tecnologica\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['EMP_BSE_TEC_P']['EBT_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['EMP_BSE_TEC_P']['EBT_P_TABLE']\n",
    "\n",
    "    format_df(df, '10.Empresarial', var_w10, writer,eh)\n",
    "        \n",
    "    var_w10 += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# empresa de base cultural\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['EMP_CRE_CUL_P']['ICC_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['EMP_CRE_CUL_P']['ICC_P_TABLE']\n",
    "\n",
    "    format_df(df, '10.Empresarial', var_w10, writer,eh)\n",
    "        \n",
    "    var_w10 += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# -------------------------w10-------------\n",
    "######  ASC\n",
    "\n",
    "# -------- w11\n",
    "# 11.ASC y Divulgación\n",
    "var_w11 = 0 \n",
    "\n",
    "# productos de interes social\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['PASC_P']['PASC_FOR_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['GEN_CONT_IMP_P']['GC_I_P_TABLE_5']\n",
    "\n",
    "    format_df(df, '11.ASC y Divulgación', var_w11, writer,eh)\n",
    "        \n",
    "    var_w11 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Proceso de apropiación social del conocimiento resultado del trabajo conjunto \n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['PASC_P']['PASC_TRA_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['PASC_P']['PASC_TRA_P_TABLE']\n",
    "\n",
    "    format_df(df, '11.ASC y Divulgación', var_w11, writer,eh)\n",
    "        \n",
    "    var_w11 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['PASC_P']['PASC_GEN_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['PASC_P']['PASC_GEN_P_TABLE']\n",
    "\n",
    "    format_df(df, '11.ASC y Divulgación', var_w11, writer,eh)\n",
    "        \n",
    "    var_w11 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['PASC_P']['PASC_CAD_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['PASC_P']['PASC_CAD_P_TABLE']\n",
    "\n",
    "    format_df(df, '11.ASC y Divulgación', var_w11, writer,eh)\n",
    "        \n",
    "    var_w11 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# Divulgacion\n",
    "# Piezas digitales\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['DC_P']['DC_CD_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['DC_P']['DC_CD_P_TABLE']\n",
    "\n",
    "    format_df(df, '11.ASC y Divulgación', var_w11, writer,eh)\n",
    "        \n",
    "    var_w11 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# textuales\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['DC_P']['DC_CON_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['DC_P']['DC_CON_P_TABLE']\n",
    "\n",
    "    format_df(df, '11.ASC y Divulgación', var_w11, writer,eh)\n",
    "        \n",
    "    var_w11 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# produccion estrategia trasmediatica\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['DC_P']['DC_TRA_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['DC_P']['DC_TRA_P_TABLE']\n",
    "\n",
    "    format_df(df, '11.ASC y Divulgación', var_w11, writer,eh)\n",
    "        \n",
    "    var_w11 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# desarrollo web\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['DC_P']['DC_DES_P_TABLE'])\n",
    "\n",
    "    eh=DBEH['ASC_P']['DC_P']['DC_DES_P_TABLE']\n",
    "\n",
    "    format_df(df, '11.ASC y Divulgación', var_w11, writer,eh)\n",
    "        \n",
    "    var_w11 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# --- --- --- -- w11 -- -- -- -- -- -- --\n",
    "\n",
    "# ---------------w12--------------------\n",
    "\n",
    "# FRH\n",
    "\n",
    "var_w12 = 0\n",
    "\n",
    "# tesis doctorado\n",
    "try:\n",
    "    df=clean_df(DBG['FRH_P']['TES_DOC_P']['TD_P_TABLE'])  ### ,veh = 2\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='FRH_P',startrow = var_rh)\n",
    "    \n",
    "    eh=DBEH['FRH_P']['TES_DOC_P']['TD_P_TABLE']\n",
    "\n",
    "    format_df(df, '12.Formación y programas', var_w12, writer, eh)\n",
    "        \n",
    "    var_w12 += df.shape[0] + 3\n",
    "\n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# tesis maestria\n",
    "try:\n",
    "    df=clean_df(DBG['FRH_P']['TES_MAST_P']['TM_P_TABLE']) ### veh = 2\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='FRH_P',startrow = var_rh)\n",
    "    \n",
    "    eh=DBEH['FRH_P']['TES_MAST_P']['TM_P_TABLE']\n",
    "\n",
    "    format_df(df, '12.Formación y programas',var_w12, writer,eh)\n",
    "        \n",
    "    var_w12 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "# tesis pregrado\n",
    "try:\n",
    "    df=clean_df(DBG['FRH_P']['TES_PREG_P']['TP_P_TABLE']) ### veh = 2\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='FRH_P',startrow = var_rh)\n",
    "    \n",
    "    eh=DBEH['FRH_P']['TES_PREG_P']['TP_P_TABLE']\n",
    "\n",
    "    format_df(df, '12.Formación y programas',var_w12, writer,eh,veh = 2)\n",
    "        \n",
    "    var_w12 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# asesoria programa academico\n",
    "try:\n",
    "    df=clean_df(DBG['FRH_P']['ASE_PRG_ACA_P']['APGA_P_TABLE']) \n",
    "    \n",
    "    eh=DBEH['FRH_P']['ASE_PRG_ACA_P']['APGA_P_TABLE']\n",
    "\n",
    "    format_df(df, '12.Formación y programas', var_w12, writer,eh)\n",
    "        \n",
    "    var_w12 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# asesoria creacion de cursos\n",
    "try:\n",
    "    df=clean_df(DBG['FRH_P']['ASE_CRE_CUR_P']['ACC_P_TABLE'])\n",
    "    \n",
    "    eh=DBEH['FRH_P']['ASE_CRE_CUR_P']['ACC_P_TABLE']\n",
    "\n",
    "    format_df(df, '12.Formación y programas', var_w12, writer,eh)\n",
    "        \n",
    "    var_w12 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# programa ondas\n",
    "try:\n",
    "    df=clean_df(DBG['FRH_P']['ASE_PRG_ONDAS_P']['APO_P_TABLE'])\n",
    "\n",
    "    eh=DBEH['FRH_P']['ASE_PRG_ONDAS_P']['APO_P_TABLE']\n",
    "\n",
    "    format_df(df, '12.Formación y programas', var_w12, writer,eh)\n",
    "        \n",
    "    var_w12 += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "#----------------w12---------------------------\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-colors",
   "metadata": {},
   "source": [
    "# ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "settled-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "schema for store tables\n",
    "\n",
    "DBG = {\n",
    "    \n",
    "    'INFO_GROUP': 'TABLE',\n",
    "    'MEMBERS':'TABLE',\n",
    "       \n",
    "    'NC_P': {'ART_IMP_P': {'ART_P_TABLE':'TABLE'},\n",
    "             'ART_ELE_P': {'ART_E_P_TABLE':'TABLE'},\n",
    "             'LIB_P':     {'LIB_P_TABLE':'TABLE'},\n",
    "             'CAP_LIB_P': {'CAP_LIB_P_TABLE':'TABLE'},\n",
    "             'NOT_CIE_P': {'NOT_CIE_P_TABLE':'TABLE'},\n",
    "             'PAT_P':     {'PAT_P_TABLE':'TABLE'},\n",
    "             'PRD_INV_ART_P': {'PAAD_P_TABLE':'TABLE'},\n",
    "             'VAR_VEG_P':     {'VV_P_TABLE':'TABLE'},\n",
    "             'VAR_ANI_P':     {'VA_P_TABLE':'TABLE'},\n",
    "             'RAZ_PEC_P':     {'RAZ_PEC_P_TABLE':'TABLE'},\n",
    "             'TRA_FIL_P': {'TRA_FIL_P_TABLE':'TABLE'}\n",
    "            },\n",
    "     'DTI_P': {'DIS_IND_P': {'DI_P_TABLE':'TABLE'},\n",
    "              'CIR_INT_P': {'ECI_P_TABLE':'TABLE'},\n",
    "              'SOFT_P': {'SF_P_TABLE':'TABLE'},\n",
    "              'NUTRA_P': {'NUTRA_P_TABLE':'TABLE'},\n",
    "              'COL_CIENT_P': {'COL_CIENT_P_TABLE':'TABLE'},\n",
    "              'REG_CIENT_P': {'REG_CIENT_P_TABLE':'TABLE'},\n",
    "              'PLT_PIL_P': {'PP_P_TABLE':'TABLE'},\n",
    "              'PRT_IND_P': {'PI_P_TABLE':'TABLE'},\n",
    "              'SEC_IND_P': {'SE_P_TABLE':'TABLE'},\n",
    "              'PROT_VIG_EPID_P': {'PROT_VIG_EPID_P_TABLE':'TABLE'},\n",
    "              'EMP_BSE_TEC_P': {'EBT_P_TABLE':'TABLE'},\n",
    "              'EMP_CRE_CUL_P': {'ICC_P_TABLE':'TABLE'},\n",
    "              'INN_GES_EMP_P': {'IG_P_TABLE':'TABLE'},\n",
    "              'INN_PROC_P': {'IPP_P_TABLE':'TABLE'},\n",
    "              'REG_NORM_REGL_LEG_P': {'RNR_P_TABLE':'TABLE'},\n",
    "              'CONP_TEC_P': {'CONP_TEC_P_TABLE':'TABLE'},\n",
    "              'REG_AAD_P': {'AAAD_P_TABLE':'TABLE'},\n",
    "              'SIG_DIS_P': {'SD_P_TABLE':'TABLE'}\n",
    "              },\n",
    "    'ASC_P': {'GEN_CONT_IMP_P': {'GC_I_P_TABLE_5':'TABLE'},\n",
    "              'PASC_P': {'PASC_FOR_P_TABLE':'TABLE',\n",
    "               'PASC_TRA_P_TABLE':'TABLE',\n",
    "               'PASC_GEN_P_TABLE':'TABLE',\n",
    "               'PASC_CAD_P_TABLE':'TABLE'},\n",
    "              'DC_P': {'DC_CD_P_TABLE':'TABLE',\n",
    "               'DC_CON_P_TABLE':'TABLE',\n",
    "               'DC_TRA_P_TABLE':'TABLE',\n",
    "               'DC_DES_P_TABLE':'TABLE'}},\n",
    "    'FRH_P': {'TES_DOC_P': {'TD_P_TABLE':'TABLE'},\n",
    "              'TES_MAST_P': {'TM_P_TABLE':'TABLE'},\n",
    "              'TES_PREG_P': {'TP_P_TABLE':'TABLE'},\n",
    "              'PROY_INV_DES_P': {'PID_P_TABLE':'TABLE'},\n",
    "              'PROY_INV_CRE_P': {'INV_CRE_P_TABLE':'TABLE'},\n",
    "              'PROY_INV_DES_INN_P': {'PF_P_TABLE':'TABLE'},\n",
    "              'PROY_INV_RESP_SOC_P': {'PE_P_TABLE':'TABLE'},\n",
    "              'ASE_PRG_ACA_P': {'APGA_P_TABLE':'TABLE'},\n",
    "              'ASE_CRE_CUR_P': {'ACC_P_TABLE':'TABLE'},\n",
    "              'ASE_PRG_ONDAS_P': {'APO_P_TABLE':'TABLE'}}\n",
    "}'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
