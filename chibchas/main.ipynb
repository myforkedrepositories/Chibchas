{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incorrect-retailer",
   "metadata": {},
   "source": [
    "# Institulac "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "brilliant-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"max_rows\",100)\n",
    "#pd.set_option(\"display.max_columns\",100)\n",
    "pd.set_option(\"max_colwidth\",1000)\n",
    "\n",
    "import helium as h\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "everyday-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICT CAT-PRODS-TAB\n",
    "with open('dict_tables.json') as file_json:\n",
    "    dict_tables=json.loads(file_json.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "polyphonic-queens",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Nombre del grupo', 'Nombre del líder', 'COL Grupo', 'Revisar'], dtype='object') (100, 4)\n",
      "Index(['Nombre del grupo', 'Nombre del líder', 'COL Grupo', 'Revisar'], dtype='object') (100, 4)\n",
      "Index(['Nombre del grupo', 'Nombre del líder', 'COL Grupo', 'Revisar'], dtype='object') (100, 4)\n",
      "Index(['Nombre del grupo', 'Nombre del líder', 'COL Grupo', 'Revisar'], dtype='object') (24, 4)\n",
      "Message: Unable to locate element: //table[@id=\"grupos_avalados\"]//tr/td[3]/a\n",
      "\n",
      "out of cicle\n"
     ]
    }
   ],
   "source": [
    "# login =\n",
    "# name_ins =\n",
    "# usser =\n",
    "# passw=\n",
    "\n",
    "# login\n",
    "browser = h.start_firefox('https://scienti.minciencias.gov.co/institulac2-war/')\n",
    "sleep=0.8\n",
    "\n",
    "#browser = h.start_firefox('https://scienti.minciencias.gov.co/institulac2-war/')\n",
    "time.sleep(sleep)\n",
    "h.click('Consulte Aquí')\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.write('UNIVERSIDAD DE ANTIOQUIA',into='Digite el nombre de la Institución') # name ins\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.click('Buscar')\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.click(browser.find_element_by_id('list_instituciones'))\n",
    "\n",
    "time.sleep(sleep)\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.select('seleccione una','UNIVERSIDAD DE ANTIOQUIA') # name_ins\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.write('annyarango',into='Usuario')                  # user\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.write('1@Silver', into='Contraseña')                # passw\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.click(h.Button('Ingresar'))\n",
    "\n",
    "# cookie injection\n",
    "time.sleep(sleep)\n",
    "# implementation cookie injection\n",
    "\n",
    "# get current cookie and store\n",
    "new_cookie=browser.get_cookies()[0]\n",
    "    \n",
    "# create new_cookie with time_expire\n",
    "time_expire = (datetime(2022,1,1) - datetime(1970,1,1)).total_seconds()\n",
    "new_cookie['expiry'] = int(time_expire)\n",
    "    \n",
    "# delete cookie sites\n",
    "browser.delete_all_cookies()\n",
    "    \n",
    "# add new cookie\n",
    "browser.add_cookie(new_cookie)\n",
    "\n",
    "# navigation 1\n",
    "time.sleep(sleep)\n",
    "h.click('Aval')\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.click('Avalar grupos')\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.click('Grupos Avalados')\n",
    "\n",
    "# -- end login --\n",
    "\n",
    "# list of total groups\n",
    "#select max results per page\n",
    "h.wait_until(h.Text('Ver Reporte').exists)\n",
    "h.click(browser.find_element_by_xpath('//table[@id=\"grupos_avalados\"]//select[@name=\"maxRows\"]'))\n",
    "\n",
    "time.sleep(sleep)\n",
    "h.select(browser.find_element_by_xpath('//table[@id=\"grupos_avalados\"]//select[@name=\"maxRows\"]'),'100')\n",
    "\n",
    "# catch 1: groups info [name, lider, cod,  link to producs]  \n",
    "# schema\n",
    "# empty df\n",
    "# select max items per page\n",
    "# while until end\n",
    "# try:\n",
    "    # catch table\n",
    "    # preproces table\n",
    "    # catch urls\n",
    "    # add url colums\n",
    "    # add df\n",
    "    # click next page -> raise error\n",
    "# except Nosuchelement:\n",
    "    # break\n",
    "    \n",
    "# catch 1: list of groups\n",
    "dfg=pd.DataFrame()\n",
    "cont=True\n",
    "\n",
    "while cont:\n",
    "    \n",
    "    try:\n",
    "        # catch source\n",
    "        time.sleep(sleep)\n",
    "        source_g=browser.page_source\n",
    "        \n",
    "        # catch table\n",
    "        time.sleep(sleep)\n",
    "        df=pd.read_html(source_g, attrs={\"id\":\"grupos_avalados\"}, header=2)[0]\n",
    "        \n",
    "        # and preprocces it\n",
    "        c=[x for x in df.columns if x.find('Unnamed:') == -1]\n",
    "        dfgp=df[c][1:-1]\n",
    "        print(dfgp.columns,dfgp.shape)\n",
    "        \n",
    "        # catch urls\n",
    "        url=[a.get_attribute('href') for a in browser.find_elements_by_xpath('//table[@id=\"grupos_avalados\"]//td[5]/a')]\n",
    "        dfgp['Revisar'] = url\n",
    "        dfg=dfg.append(dfgp)\n",
    "        \n",
    "        # click next page. this instruction rise error of the end. \n",
    "        h.click(browser.find_element_by_xpath('//table[@id=\"grupos_avalados\"]//tr/td[3]/a'))\n",
    "        \n",
    "    except NoSuchElementException as e:\n",
    "        \n",
    "        print(e)\n",
    "        print('out of cicle')\n",
    "        break\n",
    "        \n",
    "    time.sleep(sleep)\n",
    "    time.sleep(sleep)\n",
    "    \n",
    "dfg = dfg.reset_index(drop=True)\n",
    "assert dfg.shape[0] == 324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "circular-conservation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grupo Tandem en Nano-bio-física \n",
      " https://scienti.minciencias.gov.co/institulac2-war/ReGrupoInstitucion/query.do?avalGr=T&codigoGrupo=&idGrupo=00000000020456\n",
      "Promoción de la Salud \n",
      " https://scienti.minciencias.gov.co/institulac2-war/ReGrupoInstitucion/query.do?avalGr=T&codigoGrupo=&idGrupo=00000000001767\n"
     ]
    }
   ],
   "source": [
    "print(dfg['Nombre del grupo'][0:1].values[0],'\\n',dfg['Revisar'][:1].values[0])\n",
    "\n",
    "print(dfg['Nombre del grupo'][-1:].values[0],'\\n',dfg['Revisar'][-1:].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "textile-malawi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15    Grupo Académico de Epidemiología Clínica\n",
       "Name: Nombre del grupo, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg['Nombre del grupo'][15:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wooden-buddy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grupo Académico de Epidemiología Clínica\n"
     ]
    }
   ],
   "source": [
    "time.sleep(sleep*2)\n",
    "\n",
    "LD = [] # \n",
    "LP = []\n",
    "LR = [] \n",
    "for idx in dfg.index[15:16]:\n",
    "    \n",
    "    # create db\n",
    "    DBG = {}\n",
    "    # part info group\n",
    "    print(dfg.loc[idx,'Nombre del grupo'])\n",
    "\n",
    "    # specific group url\n",
    "    time.sleep(sleep)\n",
    "    url_group = dfg.loc[idx,'Revisar']\n",
    "\n",
    "    # go to url group\n",
    "    time.sleep(sleep)\n",
    "    browser.get(url_group)\n",
    "\n",
    "    # catch two tables: info grupo and  members\n",
    "    source=browser.page_source\n",
    "\n",
    "    #info\n",
    "    l_info=pd.read_html(source, match='Nombre Grupo')\n",
    "    info_g=l_info[3].pivot(columns=0,values=1)\n",
    "    \n",
    "    # STORE INFO_GROUP\n",
    "    DBG['Info_group'] = info_g\n",
    "\n",
    "    # members\n",
    "    l_int = pd.read_html(source,attrs={'id':'tblIntegrantes'},header=2)\n",
    "    mem_g=l_int[0]\n",
    "    \n",
    "    # STORE_MEMBERS\n",
    "    DBG['Members'] =  mem_g\n",
    "\n",
    "    # Products\n",
    "\n",
    "    #time.sleep(sleep*5) # time time time !!!\n",
    "    h.wait_until(lambda: browser.find_element_by_xpath('//td[@id=\"bodyPrincipal\"]//a[text()=\"Ver productos\"]') is not None)\n",
    "    h.click(browser.find_element_by_xpath('//td[@id=\"bodyPrincipal\"]//a[text()=\"Ver productos\"]'))\n",
    "\n",
    "    # products by belongs to  # time time time\n",
    "    #time.sleep(sleep*7)       # time time time\n",
    "    h.wait_until(lambda: browser.find_element_by_xpath('//*[@id=\"ProdsPertenecia\"]') is not None)\n",
    "    h.click(browser.find_element_by_xpath('//*[@id=\"ProdsPertenecia\"]'))\n",
    "\n",
    "    time.sleep(sleep)\n",
    "    url_products=browser.current_url\n",
    "\n",
    "\n",
    "    # map all products, store those id categories that amount is different to 0 and id products asociated.\n",
    "    # make queries with combinations of categories and products\n",
    "    # make urls with diferent combinations of quieries\n",
    "    # go to each of urls\n",
    "    # load page source\n",
    "    # catch table ( or tables) asociated with categories and products\n",
    "    # store tables\n",
    "\n",
    "    report = ''\n",
    "\n",
    "    list_of_prods =[] #[[cat,prod],[cat,prod]...]\n",
    "\n",
    "    # map all products and get products and subs diff to cero\n",
    "    for i in browser.find_elements_by_xpath('//div[@id=\"accordionCatgP\"]/h3'):\n",
    "\n",
    "        report += i.text + '\\n' \n",
    "        report += i.get_attribute('id') + '\\n'     \n",
    "\n",
    "        time.sleep(sleep)\n",
    "        h.click(i)\n",
    "        \n",
    "        # cat\n",
    "        cat_ = int(re.findall(r'\\d+',i.text)[0])\n",
    "        \n",
    "        # create cat key in dict, for estore diferents products by this categori: 'NC_': {'ART_E':TABLE,\n",
    "        #                                                                                 'ART_IMP':TABLE}\n",
    "        if cat_ > 0:\n",
    "            DBG[i.get_attribute('id')] = {}\n",
    "            \n",
    "        \n",
    "        for j in browser.find_elements_by_xpath('//div[@aria-labelledby=\"%s\"]/h3' % i.get_attribute('id')):\n",
    "\n",
    "            report += '\\t' + j.text + '\\n' \n",
    "            report += '\\t' + j.get_attribute('id') + '\\n'\n",
    "            \n",
    "            #prod\n",
    "            pro_ = int(re.findall(r'\\d+', j.text)[0])\n",
    "\n",
    "            if cat_ > 0 and pro_ > 0:  \n",
    "                \n",
    "                list_of_prods.append([i.get_attribute('id'),j.get_attribute('id')])\n",
    "\n",
    "        time.sleep(sleep) \n",
    "        # h.click(a)\n",
    "        h.click(i)\n",
    "\n",
    "    # print(report)\n",
    "    # print('\\n')\n",
    "    # print('--------------------------------')\n",
    "    time.sleep(sleep*2)\n",
    "    \n",
    "    tables=[]\n",
    "    \n",
    "    for p in range(len(list_of_prods)):\n",
    "\n",
    "            # make query \n",
    "            query='categoriaP=%s&subcategoriaP=%s&aval=P' % (list_of_prods[p][0],list_of_prods[p][1])\n",
    "\n",
    "            # make url query\n",
    "            url_query = url_products.split('?')[0] + '?' + query + '&' + url_products.split('?')[1]\n",
    "\n",
    "            # retrieve id asociated tables\n",
    "            table_id = dict_tables[list_of_prods[p][0]][list_of_prods[p][1]]\n",
    "\n",
    "            # go to url product by group\n",
    "            time.sleep(sleep)\n",
    "        \n",
    "            browser.get(url_query)\n",
    "\n",
    "            # load page\n",
    "            time.sleep(sleep)\n",
    "            page_source = browser.page_source\n",
    "\n",
    "            # catch tables\n",
    "            if isinstance(table_id,str): # case one table\n",
    "\n",
    "                # catch title table\n",
    "                \n",
    "                title_table = browser.find_element_by_xpath('//div/p[@class=\"titulo_tabla\"]').text \n",
    "                # cathc table\n",
    "                #print(table_id)\n",
    "                time.sleep(sleep*2)\n",
    "                table = pd.read_html(page_source,attrs={'id':table_id}, header=2)[0][1:-1]\n",
    "\n",
    "                # store table\n",
    "                DBG[list_of_prods[p][0]][list_of_prods[p][1]] = {table_id:table}\n",
    "                # ---- in building ----\n",
    "\n",
    "            elif isinstance(table_id, list): # case multiple tables\n",
    "\n",
    "                for i in range(len(table_id)):\n",
    "\n",
    "                    # catch title specific table \n",
    "                    title_table = browser.find_elements_by_xpath('//div/p[@class=\"titulo_tabla\"]')[i].text\n",
    "\n",
    "                    # catch table\n",
    "                    table = pd.read_html(page_source,attrs={'id':table_id[i]}, header=2)[0][1:-1]\n",
    "\n",
    "                    # store table\n",
    "                    DBG[list_of_prods[p][0]][list_of_prods[p][1]] = {table_id[i]:table}\n",
    "                    # -----------\n",
    "    LD.append(DBG)\n",
    "    LP.append(list_of_prods)\n",
    "    LR.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "productive-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo Conocimiento (57)\n",
      "NC_P\n",
      "\tArtículos publicados en revistas especializadas - Impresos (19)\n",
      "\tART_IMP_P\n",
      "\tArtículos publicados en revistas especializadas - Electrónicos (32)\n",
      "\tART_ELE_P\n",
      "\tLibros resultado de investigación (1)\n",
      "\tLIB_P\n",
      "\tCapítulos en Libro resultado de investigación (5)\n",
      "\tCAP_LIB_P\n",
      "\tNotas científicas (0)\n",
      "\tNOT_CIE_P\n",
      "\tPatentes (0)\n",
      "\tPAT_P\n",
      "\tObras o productos de investigación creación en Artes, Arquitectura y Diseño (0)\n",
      "\tPRD_INV_ART_P\n",
      "\tVariedad Vegetal (0)\n",
      "\tVAR_VEG_P\n",
      "\tNueva Raza Animal (0)\n",
      "\tVAR_ANI_P\n",
      "\tPoblaciones mejoradas de razas pecuarias (0)\n",
      "\tRAZ_PEC_P\n",
      "\tTraducciones Filológicas y Edición de Fuentes (0)\n",
      "\tTRA_FIL_P\n",
      "Desarrollo Tecnológico e Innovación (0)\n",
      "DTI_P\n",
      "\tDiseño industrial (0)\n",
      "\tDIS_IND_P\n",
      "\tCircuitos integrados (0)\n",
      "\tCIR_INT_P\n",
      "\tSoftware (0)\n",
      "\tSOFT_P\n",
      "\tProductos nutraceúticos (0)\n",
      "\tNUTRA_P\n",
      "\tColecciones científicas (0)\n",
      "\tCOL_CIENT_P\n",
      "\tNuevos registros científicos (0)\n",
      "\tREG_CIENT_P\n",
      "\tPlanta Piloto (0)\n",
      "\tPLT_PIL_P\n",
      "\tPrototipo Industrial (0)\n",
      "\tPRT_IND_P\n",
      "\tSecreto Industrial (0)\n",
      "\tSEC_IND_P\n",
      "\tProtocolos de vigilancia epidemiológica (0)\n",
      "\tPROT_VIG_EPID_P\n",
      "\tEmpresas de base tecnológica (0)\n",
      "\tEMP_BSE_TEC_P\n",
      "\tEmpresas creativas y culturales (0)\n",
      "\tEMP_CRE_CUL_P\n",
      "\tInnovaciones generadas en la gestión empresarial (0)\n",
      "\tINN_GES_EMP_P\n",
      "\tInnovaciones en procesos o procedimientos (0)\n",
      "\tINN_PROC_P\n",
      "\tRegulaciones, normas, reglamentos o legislaciones (0)\n",
      "\tREG_NORM_REGL_LEG_P\n",
      "\tConceptos técnicos (0)\n",
      "\tCONP_TEC_P\n",
      "\tRegistros de Acuerdos de licencia para la explotación de obras de AAD (0)\n",
      "\tREG_AAD_P\n",
      "\tSignos distintivos (0)\n",
      "\tSIG_DIS_P\n",
      "Apropiación social del conocimiento y Divulgación Pública de la Ciencia (24)\n",
      "ASC_P\n",
      "\tGeneración de contenido impreso (2)\n",
      "\tGEN_CONT_IMP_P\n",
      "\tEventos Científicos (9)\n",
      "\tEV_CIENT_P\n",
      "\tRed de conocimiento especializado (1)\n",
      "\tRED_P\n",
      "\tTalleres de creación (0)\n",
      "\tTALL_CRE_P\n",
      "\tEventos Artísticos (0)\n",
      "\tEVE_ART_P\n",
      "\tDocumento de trabajo (12)\n",
      "\tDOC_TRAB_P\n",
      "\tNuevas secuencias genéticas (0)\n",
      "\tSEC_GENE_P\n",
      "\tBoletín divulgativo de resultado de investigación (0)\n",
      "\tBOL_RES_INV_P\n",
      "\tConsultoría cientìfico tecnológica (0)\n",
      "\tCON_INF_TEC_P\n",
      "\tEdición (0)\n",
      "\tEDIC_P\n",
      "\tInformes (0)\n",
      "\tINF_TEC_P\n",
      "\tProcesos de apropiación social del conocimiento (PASC) (0)\n",
      "\tPASC_P\n",
      "\tProductos de divulgación pública de la ciencia (0)\n",
      "\tDC_P\n",
      "Formación del Recurso Humano (53)\n",
      "FRH_P\n",
      "\tDirecciones de tesis de doctorado (2)\n",
      "\tTES_DOC_P\n",
      "\tDirecciones de trabajo de grado de maestría (33)\n",
      "\tTES_MAST_P\n",
      "\tDirecciones de trabajos de pregrado (0)\n",
      "\tTES_PREG_P\n",
      "\tProyecto de investigación y desarrollo (7)\n",
      "\tPROY_INV_DES_P\n",
      "\tProyecto de investigación + creación (0)\n",
      "\tPROY_INV_CRE_P\n",
      "\tProyecto de investigación, desarrollo e innovación (ID+I) (0)\n",
      "\tPROY_INV_DES_INN_P\n",
      "\tProyecto de extensión y de responsabilidad social en CTeI (0)\n",
      "\tPROY_INV_RESP_SOC_P\n",
      "\tApoyo a la creación de programas académicos (0)\n",
      "\tASE_PRG_ACA_P\n",
      "\tApoyo a la creación de cursos (11)\n",
      "\tASE_CRE_CUR_P\n",
      "\tAcompañamiento y asesoría de línea temática del Programa Ondas (0)\n",
      "\tASE_PRG_ONDAS_P\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(LR[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "driving-chest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TES_DOC_P': {'TD_P_TABLE':   Unnamed: 0  \\\n",
       "  1          1   \n",
       "  2          2   \n",
       "  \n",
       "                                                                                                                                                                                                                                                                                          Título  \\\n",
       "  1  Eficacia del Entrenamiento Aeróbico de Intervalos de Alta Intensidad (eAIAI) En Comparación con el Aeróbico Continuo (eAC) sobre la resistencia a la insulina, estructura y función del músculo esquelético en adultos con síndrome metabólico (SM): un ensayo clínico controlado aleatorio   \n",
       "  2                                                                                                                                                                                     Efecto moderador de las funciones ejecutivas en la relación entre condiciones laborales y estrés laboral   \n",
       "  \n",
       "                            Autor  \\\n",
       "  1  Jaime Alberto Gallo Villegas   \n",
       "  2          Lucila Cárdenas Niño   \n",
       "  \n",
       "                                         Institución  \\\n",
       "  1                         UNIVERSIDAD DE ANTIOQUIA   \n",
       "  2  UNIVERSIDAD DE SAN BUENAVENTURA - SEDE MEDELLÍN   \n",
       "  \n",
       "                          Director Fecha inicio Fecha fin        Reconocimiento  \\\n",
       "  1  Daniel Camilo Aguirre Acevedo       2017-3   2020-12   Distinción laureada   \n",
       "  2  Daniel Camilo Aguirre Acevedo       2014-8   2020-12  Distinción meritoria   \n",
       "  \n",
       "    Categoría Última actualización Revisar  \n",
       "  1       NaN           2021-04-19     NaN  \n",
       "  2       NaN           2021-04-19     NaN  },\n",
       " 'TES_MAST_P': {'TM_P_TABLE':    Unnamed: 0  \\\n",
       "  1           1   \n",
       "  2           2   \n",
       "  3           3   \n",
       "  4           4   \n",
       "  5           5   \n",
       "  6           6   \n",
       "  7           7   \n",
       "  8           8   \n",
       "  9           9   \n",
       "  10         10   \n",
       "  11         11   \n",
       "  12         12   \n",
       "  13         13   \n",
       "  14         14   \n",
       "  15         15   \n",
       "  16         16   \n",
       "  17         17   \n",
       "  18         18   \n",
       "  19         19   \n",
       "  20         20   \n",
       "  21         21   \n",
       "  22         22   \n",
       "  23         23   \n",
       "  24         24   \n",
       "  25         25   \n",
       "  26         26   \n",
       "  27         27   \n",
       "  28         28   \n",
       "  29         29   \n",
       "  30         30   \n",
       "  31         31   \n",
       "  32         32   \n",
       "  33         33   \n",
       "  \n",
       "                                                                                                                                                                                                                                                                                                           Título  \\\n",
       "  1   Diseño y validación de modelo predictivo de resistencia antimicrobiana mediada por betalactamasas de espectro extendido (BLEE) en enterobacterias aisladas por urocultivo de pacientes adultos que consultan al servicio de urgencias por infección urinaria en hospitales del área metropolitana. Medellín   \n",
       "  2                                                                                                                                                                                             Asociación de variables clínicas de hipoperfusión con el lactato, su depuración y la mortalidad intrahospitalaria   \n",
       "  3                                                                                                                                                                                             Asociación de variables clínicas de hipoperfusión con el lactato, su depuración y la mortalidad intrahospitalaria   \n",
       "  4                                                                                                                                                                                                 Uso adecuado de antibióticos en pacientes con sepsis grave y choque séptico: estudio de cohorte retrospectivo   \n",
       "  5                                                                                                                                                    Validación y comparación de 3 puntajes predictores de mortalidad en pacientes con neumonía adquirida en la comunidad atendidos en el servicio de urgencias   \n",
       "  6                                                                                                                                                         ESTUDIO DE PRUEBAS DIAGNÓSTICAS PARA EVALUAR LA DERMATOSCOPIA FRENTE A LA BIOPSIA DE CUERO CABELLUDO EN EL DIAGNÓSTICO DE ALOPECIA EN PATRÓN FEMENINO   \n",
       "  7                                                                                                                                                                                              Validación de la escala de autoestigma por búsqueda de ayuda en población de estudiantes de medicina de Colombia   \n",
       "  8                                      Validación de un instrumento para identificar barreras y facilitadores de la implementación de la Guía de Práctica Clínica para el diagnóstico y tratamiento preoperatorio, intraoperatorio y postoperatorio de la persona amputada, la prescripción de la prótesis y la   \n",
       "  9                                                                                                                                                                                                                    Factores genéticos y no genéticos asociados a cadasil: un estudio de cohorte retrospectivo   \n",
       "  10                                                                          Factores de riesgo clínicos para el desarrollo de infecciones por bacilos Gram negativos multirresistentes en la población pediátrica de un hospital de alta complejidad en Medellín, Colombia. Estudio retrospectivo observacional   \n",
       "  11                                                                                                                               Caracterización clínica de los pacientes pediátricos con infecciones invasoras por Staphylococcus aureus en hospitales de alta complejidad de Medellín en los años 2014 y 2015   \n",
       "  12                                                                                                                                                    Relación entre algunas características socioculturales y la violencia de pareja según condición socioeconómica a nivel individual y de barrio en Medellín   \n",
       "  13                                                                                                                                                                                      Factores de riesgo asociados con muerte o morbilidad grave en niños con infecciones invasoras por staphylococcus aureus   \n",
       "  14                                                                                                                                                        Caracterización de las infecciones en niños menores de 60 meses con desnutrición aguda grave, hospitalizados en 2 instituciones de salud de Antioquía   \n",
       "  15                                                                                                                                                                                                             Comportamiento de la escala de riesgo del consenso de la SLIPE en niños con neutropenia y fiebre   \n",
       "  16                                                                                                                                 Características clínicas y del electroencefalograma de amplitud integrada en recién nacidos con encefalopatía hipóxico-isquémica bajo protocolo de hipotermia corporal total   \n",
       "  17                                                                                                                                                                                                                Correlación entre la edad ósea y la edad cronológica en una muestra de niños antioqueños   \n",
       "  18                                                                                                                                                                                 Herramienta metodológica de evaluación para la incorporación de dispositivos médicos para instituciones de salud de Medellín   \n",
       "  19                                                                                                                                                                                               ¿\\tAtenuación de la respuesta fisiológica a la infección en adultos mayores de 65 años admitidos por urgencias   \n",
       "  20                                                                                                                                   ¿\\tDescripción de pacientes con ataque cerebrovascular isquémico llevados a trombolisis intravenosa entre enero de 2011 a diciembre 2015 en la IPS Universitaria León XIII   \n",
       "  21                                                                                                                                                                              Trombolisis en infarto con elevación del segmento ST: Mortalidad y sangrado en un centro de referencia de la ciudad de Medellín   \n",
       "  22                                                                                                                                                                                                Validación de la sexta edición del índice de gravedad de la adicción (ISA-6) en población cínica de Antioquia   \n",
       "  23                                                                                                                                                                       ¿\\tValidez de Constructo y Sensibilidad al Cambio de la Versión Colombiana del Cuestionario para Calidad de Vida Skindex-29, 2016-2017   \n",
       "  24                                                                                                                                                      ¿\\tSituación del sistema de vigilancia epidemiológico de la malaria en la zona de frontera colombo-peruana en el año 2017: un estudio de métodos mixtos   \n",
       "  25                                                                                                                                                      Uso de anticonvulsivantes en el tratamiento hospitalario de pacientes con síndrome de abstinencia alcohólica: Una revisión sistemática de la literatura   \n",
       "  26                                                                                                                                                                                            Experiencias diferenciales y factores de adversidad psicosocial asociados al TDAH en una población de alto riesgo   \n",
       "  27                                                                                                                                                                         Resonancia magnética funcional en estado de reposo en el trastorno afectivo bipolar: la influencia del número de episodios afectivos   \n",
       "  28                                                                                                                                                                                             Neuroimagen estructural y polaridad predominante en pacientes con Trastorno Afectivo Bipolar tipo I de Antioquia   \n",
       "  29                                                                                                                                                    Correlación entre el desempeño cognitivo y la neuroanatomía estructural en pacientes con trastorno afectivo bipolar tipo I tratados con litio y sin litio   \n",
       "  30                                                                                                                                                                                Determinación empírica de subtipos del Trastorno Afectivo Bipolar en un aislado genético paisa: la influencia de la ancestría   \n",
       "  31                                                                                                                                                                                                                                        Eventos vitales y síntomas psiquiátricos en hijos de padres bipolares   \n",
       "  32                                                                                                                                                                                                          Evaluación longitudinal de los factores asociados con la mortalidad en la intoxicación por Paraquat   \n",
       "  33                                                                                                                                                                        Características y complicaciones de la intoxicación aguda por cocaína: un estudio transversal en un servicio de urgencias de Colombia   \n",
       "  \n",
       "                                                                Autor  \\\n",
       "  1                                   Sebastián Fernando Niño Ramírez   \n",
       "  2                                          Cesar Daniel Niño Pulido   \n",
       "  3                                     Jessica María Londoño Agudelo   \n",
       "  4                                    Pablo Alberto Castaño Ceballos   \n",
       "  5                                          Carolina Hincapié Osorno   \n",
       "  6                                     Gener Alejandro Mancilla Diaz   \n",
       "  7                                  Brayan Fernando Larrahondo Erazo   \n",
       "  8                                          Ana María Posada Borrero   \n",
       "  9                                          Carolina Ospina Villegas   \n",
       "  10            Jonahtan Alexis Jurado García, Laura Morales Valencia   \n",
       "  11                  Mariana Duque Yepes, Laura Fernanda Niño Jaimes   \n",
       "  12                                      Catalina Echeverry Querubín   \n",
       "  13             Diana María Gómez Flórez, Claudia María Zapata Muñoz   \n",
       "  14          Natalia Fernández Monsalve, Katia Esther Zarza Cantillo   \n",
       "  15                                 Maira Lizeth Hinestroza Palomino   \n",
       "  16  Isabel Cristina Pareja Betancur, Kaarem Dayanna Gutierrez Amaya   \n",
       "  17                                             Carolina Henao Ochoa   \n",
       "  18                                   Paula Andrea Lizcano Jaramillo   \n",
       "  19                                         Alejandro Marín Valencia   \n",
       "  20                                Andrés Felipe Hernández Jaramillo   \n",
       "  21                                      Maria Nelly Milfort Blandón   \n",
       "  22                                         Juan Pablo Zapata Ospina   \n",
       "  23                                  Daniel Alberto Vásquez Hincapié   \n",
       "  24                                            Mónica Rondón Cotacio   \n",
       "  25                                        Jenny Alexandra Rojo Mira   \n",
       "  26                                        Guillermo Ramírez Jiménez   \n",
       "  27                                            Marcela Ángel Escobar   \n",
       "  28                                           Giancarlo Carreño Ruiz   \n",
       "  29                                         Andrés Camilo Díaz Ortiz   \n",
       "  30                                   Laura Margarita Ovadia Cardona   \n",
       "  31                                         Sara Velásquez Jaramillo   \n",
       "  32                                 Edna Carolina Chinchilla Escobar   \n",
       "  33                                             Laura Jiménez Ospina   \n",
       "  \n",
       "                   Institución                        Director Fecha inicio  \\\n",
       "  1   UNIVERSIDAD DE ANTIOQUIA       Héctor Iván García García       2017-1   \n",
       "  2   UNIVERSIDAD DE ANTIOQUIA  Fabian Alberto Jaimes Barragan       2014-6   \n",
       "  3   UNIVERSIDAD DE ANTIOQUIA  Fabian Alberto Jaimes Barragan       2014-6   \n",
       "  4   UNIVERSIDAD DE ANTIOQUIA  Fabian Alberto Jaimes Barragan       2014-6   \n",
       "  5   UNIVERSIDAD DE ANTIOQUIA  Fabian Alberto Jaimes Barragan       2016-6   \n",
       "  6   UNIVERSIDAD DE ANTIOQUIA         Gloria Sanclemente Mesa       2009-8   \n",
       "  7   UNIVERSIDAD DE ANTIOQUIA           Jenny García Valencia       2018-2   \n",
       "  8   UNIVERSIDAD DE ANTIOQUIA   Daniel Camilo Aguirre Acevedo       2016-8   \n",
       "  9   UNIVERSIDAD DE ANTIOQUIA   Daniel Camilo Aguirre Acevedo       2017-7   \n",
       "  10  UNIVERSIDAD DE ANTIOQUIA  Javier Orlando CONTRERAS ORTIZ       2015-8   \n",
       "  11  UNIVERSIDAD DE ANTIOQUIA  Javier Orlando CONTRERAS ORTIZ       2013-8   \n",
       "  12  UNIVERSIDAD DE ANTIOQUIA  Javier Orlando CONTRERAS ORTIZ       2015-1   \n",
       "  13  UNIVERSIDAD DE ANTIOQUIA  Javier Orlando CONTRERAS ORTIZ       2015-8   \n",
       "  14  UNIVERSIDAD DE ANTIOQUIA  Javier Orlando CONTRERAS ORTIZ       2015-8   \n",
       "  15  UNIVERSIDAD DE ANTIOQUIA  Javier Orlando CONTRERAS ORTIZ       2016-8   \n",
       "  16  UNIVERSIDAD DE ANTIOQUIA  Javier Orlando CONTRERAS ORTIZ       2016-8   \n",
       "  17  UNIVERSIDAD DE ANTIOQUIA  Javier Orlando CONTRERAS ORTIZ       2016-8   \n",
       "  18           UNIVERSIDAD EIA  Javier Orlando CONTRERAS ORTIZ       2018-3   \n",
       "  19  UNIVERSIDAD DE ANTIOQUIA           Claudia Marcela Vélez       2015-8   \n",
       "  20  UNIVERSIDAD DE ANTIOQUIA           Claudia Marcela Vélez       2015-8   \n",
       "  21  UNIVERSIDAD DE ANTIOQUIA           Claudia Marcela Vélez       2017-8   \n",
       "  22  UNIVERSIDAD DE ANTIOQUIA           Claudia Marcela Vélez       2015-8   \n",
       "  23  UNIVERSIDAD DE ANTIOQUIA           Claudia Marcela Vélez       2015-8   \n",
       "  24  UNIVERSIDAD DE ANTIOQUIA           Claudia Marcela Vélez       2016-8   \n",
       "  25  UNIVERSIDAD DE ANTIOQUIA        Juan Pablo Zapata Ospina       2017-1   \n",
       "  26  UNIVERSIDAD DE ANTIOQUIA        Juan Pablo Zapata Ospina       2018-1   \n",
       "  27  UNIVERSIDAD DE ANTIOQUIA        Juan Pablo Zapata Ospina       2017-8   \n",
       "  28  UNIVERSIDAD DE ANTIOQUIA        Juan Pablo Zapata Ospina       2017-8   \n",
       "  29  UNIVERSIDAD DE ANTIOQUIA        Juan Pablo Zapata Ospina       2017-8   \n",
       "  30  UNIVERSIDAD DE ANTIOQUIA        Juan Pablo Zapata Ospina       2017-8   \n",
       "  31  UNIVERSIDAD DE ANTIOQUIA        Juan Pablo Zapata Ospina       2017-8   \n",
       "  32  UNIVERSIDAD DE ANTIOQUIA        Juan Pablo Zapata Ospina       2017-8   \n",
       "  33  UNIVERSIDAD DE ANTIOQUIA        Juan Pablo Zapata Ospina       2017-8   \n",
       "  \n",
       "     Fecha fin       Reconocimiento Categoría Última actualización Revisar  \n",
       "  1     2019-4             Aprobada       NaN           2020-11-01     NaN  \n",
       "  2     2016-6             Aprobada      TM_B           2017-02-07     NaN  \n",
       "  3     2016-6             Aprobada       NaN           2017-02-07     NaN  \n",
       "  4     2016-6             Aprobada       NaN           2017-02-07     NaN  \n",
       "  5     2019-4             Aprobada       NaN           2020-08-24     NaN  \n",
       "  6     2011-8             Aprobada       NaN           2020-10-20     NaN  \n",
       "  7     2019-9  Distinción laureada       NaN           2020-05-10     NaN  \n",
       "  8     2019-8             Aprobada       NaN           2020-11-01     NaN  \n",
       "  9     2020-7  Distinción laureada       NaN           2020-08-28     NaN  \n",
       "  10    2018-8             Aprobada      TM_B           2019-03-06     NaN  \n",
       "  11    2016-7             Aprobada      TM_B           2019-03-06     NaN  \n",
       "  12    2018-7             Aprobada      TM_B           2019-03-06     NaN  \n",
       "  13    2018-7             Aprobada       NaN           2019-09-04     NaN  \n",
       "  14    2018-7             Aprobada       NaN           2019-09-04     NaN  \n",
       "  15    2019-7             Aprobada       NaN           2019-09-04     NaN  \n",
       "  16    2019-7             Aprobada       NaN           2019-09-04     NaN  \n",
       "  17    2018-7             Aprobada       NaN           2019-09-05     NaN  \n",
       "  18    2019-7             Aprobada       NaN           2019-09-05     NaN  \n",
       "  19    2017-8             Aprobada       NaN           2020-08-06     NaN  \n",
       "  20    2017-8             Aprobada       NaN           2020-08-06     NaN  \n",
       "  21    2019-8             Aprobada       NaN           2020-08-06     NaN  \n",
       "  22    2017-8             Aprobada       NaN           2020-08-06     NaN  \n",
       "  23    2017-8             Aprobada       NaN           2020-08-06     NaN  \n",
       "  24    2018-8             Aprobada       NaN           2020-08-06     NaN  \n",
       "  25   2018-12             Aprobada       NaN           2019-02-02     NaN  \n",
       "  26    2019-6             Aprobada       NaN           2019-06-17     NaN  \n",
       "  27    2020-6             Aprobada       NaN           2020-07-14     NaN  \n",
       "  28    2020-6             Aprobada       NaN           2020-07-14     NaN  \n",
       "  29    2020-6             Aprobada       NaN           2020-07-14     NaN  \n",
       "  30    2020-6             Aprobada       NaN           2020-07-14     NaN  \n",
       "  31    2020-6             Aprobada       NaN           2020-07-14     NaN  \n",
       "  32    2020-6             Aprobada       NaN           2020-07-14     NaN  \n",
       "  33    2020-6             Aprobada       NaN           2020-07-14     NaN  },\n",
       " 'PROY_INV_DES_P': {'PID_P_TABLE':   Unnamed: 0  \\\n",
       "  1          1   \n",
       "  2          2   \n",
       "  3          3   \n",
       "  4          4   \n",
       "  5          5   \n",
       "  6          6   \n",
       "  7          7   \n",
       "  \n",
       "                                                                                                                                                                                               Nombre  \\\n",
       "  1                                                                Hallazgos radiológicos en pacientes con exacerbación de EPOC como factores determinantes de morbimortalidad. Un estudio de cohorte   \n",
       "  2                                                                                                                                     Partners for Evidence-driven Rapid Learning in Social Systems   \n",
       "  3                        Implementation of prioritized health systems- related recommendations from WHO Health System Guidelines and from Colombian Ministry of Health Clinical Practice Guidelines   \n",
       "  4                                        Percepciones ciudadanas sobre tecnologías y servicios a ser cubiertos con recursos públicos del sistema de salud, y rol de la evidencia en su modificación   \n",
       "  5  Desarrollo, implementación y evaluación de una estrategia de transferencia del conocimiento para apoyar la toma de decisiones políticas informadas por la evidencia a nivel nacional en Colombia   \n",
       "  6                                                                                                                       Validación de la Escala de Acoso Escolar EAE para Adolescentes en Colombia.   \n",
       "  7                                                                    Guía de Práctica Clínica para el diagnóstico y tratamiento de rehabilitación de las personas mayores de 7 años con baja visión   \n",
       "  \n",
       "      Inicio Finalización Instituciones Categoría Última actualización Revisar  \\\n",
       "  1  2017-12          NaN             1       NaN           2019-12-20     NaN   \n",
       "  2   2019-2          NaN             2       NaN           2020-08-23     NaN   \n",
       "  3   2019-9          NaN             2       NaN           2020-08-06     NaN   \n",
       "  4  2019-12          NaN             2       NaN           2020-08-06     NaN   \n",
       "  5   2020-5          NaN             2       NaN           2020-08-06     NaN   \n",
       "  6   2020-9          NaN             2       NaN           2020-11-02     NaN   \n",
       "  7   2019-1      2020-12             1       NaN           2021-04-18     NaN   \n",
       "  \n",
       "     Unnamed: 8  \n",
       "  1         NaN  \n",
       "  2         NaN  \n",
       "  3         NaN  \n",
       "  4         NaN  \n",
       "  5         NaN  \n",
       "  6         NaN  \n",
       "  7         NaN  },\n",
       " 'ASE_CRE_CUR_P': {'ACC_P_TABLE':    Unnamed: 0       Tipo  \\\n",
       "  1           1  Doctorado   \n",
       "  2           2  Doctorado   \n",
       "  3           3  Doctorado   \n",
       "  4           4  Doctorado   \n",
       "  5           5  Doctorado   \n",
       "  6           6  Doctorado   \n",
       "  7           7  Doctorado   \n",
       "  8           8  Doctorado   \n",
       "  9           9  Doctorado   \n",
       "  10         10  Doctorado   \n",
       "  11         11  Doctorado   \n",
       "  \n",
       "                                                        Nombre del curso  \\\n",
       "  1                              Tópicos Específicos 3: neuropsiquiatria   \n",
       "  2   Tópicos Específicos 3: Modelos Clínicos y Enfermedades Infecciosas   \n",
       "  3                                                      Investigación 4   \n",
       "  4                                                      Investigación 5   \n",
       "  5                                                      Investigación 3   \n",
       "  6                                                     Bioestadística 2   \n",
       "  7                                                      Investigación 2   \n",
       "  8                              Tópicos Específicos 1: neuropsiquiatria   \n",
       "  9   Tópicos Específicos 2: Modelos Clínicos y Enfermedades Infecciosas   \n",
       "  10                                                           Métodos 2   \n",
       "  11                             Tópicos Específicos 4: neuropsiquiatria   \n",
       "  \n",
       "                 Programa académico               Institución  \\\n",
       "  1   Doctorado en Medicina Clínica  Universidad de Antioquia   \n",
       "  2   Doctorado en Medicina Clínica  Universidad de Antioquia   \n",
       "  3   Doctorado en Medicina Clínica  Universidad de Antioquia   \n",
       "  4   Doctorado en Medicina Clínica  Universidad de Antioquia   \n",
       "  5   Doctorado en Medicina Clínica  Universidad de Antioquia   \n",
       "  6   Doctorado en Medicina Clínica  Universidad de Antioquia   \n",
       "  7   Doctorado en Medicina Clínica  Universidad de Antioquia   \n",
       "  8   Doctorado en Medicina Clínica  Universidad de Antioquia   \n",
       "  9   Doctorado en Medicina Clínica  Universidad de Antioquia   \n",
       "  10  Doctorado en Medicina Clínica  Universidad de Antioquia   \n",
       "  11  Doctorado en Medicina Clínica  Universidad de Antioquia   \n",
       "  \n",
       "     Acto administrativo       Fecha Categoría Última actualización Revisar  \n",
       "  1              56-2020  2020-03-03       NaN           2020-09-22     NaN  \n",
       "  2              51-2019  2019-12-03       NaN           2020-09-22     NaN  \n",
       "  3              66-2020  2020-08-04       NaN           2020-09-22     NaN  \n",
       "  4              66-2020  2020-08-04       NaN           2020-09-22     NaN  \n",
       "  5              64-2020  2020-07-21       NaN           2020-09-22     NaN  \n",
       "  6              51-2019  2019-12-03       NaN           2020-09-22     NaN  \n",
       "  7              51-2019  2019-12-03       NaN           2020-09-22     NaN  \n",
       "  8              39-2019  2019-05-14       NaN           2020-09-22     NaN  \n",
       "  9              51-2019  2019-12-03       NaN           2020-09-22     NaN  \n",
       "  10             53-2020  2020-01-21       NaN           2020-09-22     NaN  \n",
       "  11             64-2020  2020-07-21       NaN           2020-09-22     NaN  }}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LD[0]['FRH_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "satisfactory-kingston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NC_P', 'ART_IMP_P'],\n",
       " ['NC_P', 'ART_ELE_P'],\n",
       " ['NC_P', 'LIB_P'],\n",
       " ['NC_P', 'CAP_LIB_P'],\n",
       " ['ASC_P', 'GEN_CONT_IMP_P'],\n",
       " ['ASC_P', 'EV_CIENT_P'],\n",
       " ['ASC_P', 'RED_P'],\n",
       " ['ASC_P', 'DOC_TRAB_P'],\n",
       " ['FRH_P', 'TES_DOC_P'],\n",
       " ['FRH_P', 'TES_MAST_P'],\n",
       " ['FRH_P', 'PROY_INV_DES_P'],\n",
       " ['FRH_P', 'ASE_CRE_CUR_P']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LP[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "collective-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(LD)==len(LP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "provincial-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(df):\n",
    "    \n",
    "    info= {\n",
    "        'Nombre_Grupo' : df['Nombre Grupo'].dropna().iloc[0],\n",
    "\n",
    "        'Nombre_Lider' : df['Nombre Líder'].dropna().iloc[0],\n",
    "\n",
    "        'Nombre_Area'  : df['Nombre área'].dropna().iloc[0]\n",
    "    }\n",
    "    \n",
    "    dfi = pd.DataFrame(info, index=[0])\n",
    "  \n",
    "    \n",
    "    return dfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "informal-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBEH = {\n",
    "    \n",
    "    'INFO_GROUP': 'TABLE',\n",
    "    'MEMBERS':['Identificación Nacionalidad','Tiene afiliación con UdeA', 'Si no tiene afiliación UdeA diligencie el nombre de la Institución','Nro. Horas de dedicación semanales que avala el Coordinador de grupo'], # 2\n",
    "       \n",
    "    'NC_P': {'ART_IMP_P': {'ART_P_TABLE':['URL','DOI','Si no tiene URL o DOI agregue una evidencia en el repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'ART_ELE_P': {'ART_E_P_TABLE':['URL','DOI','Si no tiene URL o DOI agregue una evidencia en el repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'LIB_P':     {'LIB_P_TABLE':['Proyecto de investigación del cual se derivó el libro (Código-Título)','Financiador(es) del proyecto del cual se derivó el libro', 'Financiador(es) de la publicación','Autores','Citas recibidas (si tiene)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'CAP_LIB_P': {'CAP_LIB_P_TABLE':['Proyecto de investigación del cual se derivó el libro que contiene el capítulo (Código-Título)','Financiador del proyecto del cual se derivó el libro que contiene el capítulo','Financiador de la publicación','Autores','Citas recibidas (si tiene)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'NOT_CIE_P': {'NOT_CIE_P_TABLE':['URL','DOI','Si no tiene URL o DOI genere una evidencia en el repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'PAT_P':     {'PAT_P_TABLE':['Autores', 'Examen de fondo favorable','Examen preliminar internacional favorable','Adjunta opiniones escritas de la bUsqueda internacional','Contrato de explotación','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}, #  123 -1\n",
    "             'PRD_INV_ART_P': {'PAAD_P_TABLE':['Autores','Tiene certificado institucional de la obra','Tiene certificado de la entidad que convoca al evento en el que participa','Tiene certificado de la entidad que convoca al premio en el que obtiene','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}, # 1 2 3 -1\n",
    "             'VAR_VEG_P':     {'VV_P_TABLE':['Autores','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'VAR_ANI_P':     {'VA_P_TABLE':['Autores','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'RAZ_PEC_P':     {'RAZ_PEC_P_TABLE':['Autores','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "             'TRA_FIL_P': {'TRA_FIL_P_TABLE':['Proyecto de investigación del cual se derivó el libro (Código-Título)','Financiador(es) del proyecto del cual se derivó el libro','Financiador(es) de la publicación','Autores','Citas recibidas (si tiene)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}\n",
    "            },\n",
    "     'DTI_P': {'DIS_IND_P': {'DI_P_TABLE':['Autores','Contrato (si aplica)','Nombre comercial (si aplica)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'CIR_INT_P': {'ECI_P_TABLE':['Autores','Contrato (si aplica)','Nombre comercial (si aplica)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'SOFT_P': {'SF_P_TABLE':['Autores','Contrato (si aplica)','Nombre comercial (si aplica)','TRL','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'NUTRA_P': {'NUTRA_P_TABLE':['Autores','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']}, # add\n",
    "              'COL_CIENT_P': {'COL_CIENT_P_TABLE':['Autores','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo', '¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'REG_CIENT_P': {'REG_CIENT_P_TABLE':['Autores','Contrato licenciamiento (si aplica)','Agregue las evidencias verificadas al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'PLT_PIL_P': {'PP_P_TABLE':['Autores','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'PRT_IND_P': {'PI_P_TABLE':['Autores','Nombre comercial (si aplica)','TRL','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'SEC_IND_P': {'SE_P_TABLE':['Autores','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'PROT_VIG_EPID_P': {'PROT_VIG_EPID_P_TABLE':['Autores','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'EMP_BSE_TEC_P': {'EBT_P_TABLE':['Autores','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'EMP_CRE_CUL_P': {'ICC_P_TABLE':['Autores','Agregue la evidencia verificada al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'INN_GES_EMP_P': {'IG_P_TABLE':['Autores','Contrato (si aplica)','Nombre comercial (si aplica)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'INN_PROC_P': {'IPP_P_TABLE':['Autores','Contrato (si aplica)','Nombre comercial (si aplica)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'REG_NORM_REGL_LEG_P': {'RNR_P_TABLE':['Autores','Contrato (si aplica)','Convenio (si aplica)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'CONP_TEC_P': {'CONP_TEC_P_TABLE':['Autores','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'REG_AAD_P': {'AAAD_P_TABLE':['Autores','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'SIG_DIS_P': {'SD_P_TABLE':['Autores','Contrato licenciamiento (si aplica)','Agregue las evidencias verificadas al repositorio digital y copie el link del archivo en este campo','¿El producto cumple con los requisitos para ser avalado?']}\n",
    "              },\n",
    "    'ASC_P': {'GEN_CONT_IMP_P': {'GC_I_P_TABLE_5':['Autores','Citas recibidas (si tiene)','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'PASC_P': {'PASC_FOR_P_TABLE':['Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?'],\n",
    "               'PASC_TRA_P_TABLE':['Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?'],\n",
    "               'PASC_GEN_P_TABLE':['Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?'],\n",
    "               'PASC_CAD_P_TABLE':['Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'DC_P': {'DC_CD_P_TABLE':['Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?'],\n",
    "               'DC_CON_P_TABLE':['Medio de verificación','Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?'],\n",
    "               'DC_TRA_P_TABLE':['Medio de verificación','Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?'],\n",
    "               'DC_DES_P_TABLE':['Medio de verificación','Proyecto/Código','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}},\n",
    "    \n",
    "    'FRH_P': {'TES_DOC_P': {'TD_P_TABLE':['Número de cédula del graduado','¿La fecha fin coincide con la fecha de grado del estudiante?','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},  # 1 -1\n",
    "              'TES_MAST_P': {'TM_P_TABLE':['Número de cédula del graduado','¿La fecha fin coincide con la fecha de grado del estudiante?','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}, # 1 -1\n",
    "              'TES_PREG_P': {'TP_P_TABLE':['Número de cédula del graduado','¿La fecha fin coincide con la fecha de grado del estudiante?','Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}, # 1 -1\n",
    "              'ASE_PRG_ACA_P': {'APGA_P_TABLE':['Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'ASE_CRE_CUR_P': {'ACC_P_TABLE':['Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']},\n",
    "              'ASE_PRG_ONDAS_P': {'APO_P_TABLE':['Agregue las evidencias verificadas al repositorio digital y genere un hipervínculo en este campo','¿El producto cumple con los requisitos para ser avalado?']}}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "korean-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "                '1': 'C',\n",
    "                '2': 'D',\n",
    "                '3': 'E',\n",
    "                '4': 'F',\n",
    "                '5': 'G',\n",
    "                '6': 'H',\n",
    "                '7': 'I',\n",
    "                '8': 'J',\n",
    "                '9': 'K',\n",
    "                '10': 'L',\n",
    "                '11': 'M',\n",
    "                '12': 'N',\n",
    "                '13': 'O',\n",
    "                '14': 'P',\n",
    "                '15': 'Q'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "illegal-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    'remove innecesari collums'\n",
    "    c=[x for x in df.columns if x.find('Unnamed:') == -1 and  x.find('Revisar') == -1]\n",
    "    dfc=df[c]\n",
    "    return dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "detected-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(df, sheet_name, start_row, writer,eh, veh =None):\n",
    "    'format headers'\n",
    "    \n",
    "    df.to_excel(writer,sheet_name, startrow = start_row+1, startcol=2,index = False)\n",
    "\n",
    "    # Get the xlsxwriter workbook and worksheet objects.\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    \n",
    "    #form merge cells\n",
    "    start,end = 1,df.shape[1]\n",
    "\n",
    "    m_range = d.get(str(start)) + str(start_row + 1) + ':' + d.get(str(end)) + str(start_row +1)\n",
    "\n",
    "    worksheet.merge_range(m_range, 'Información suministrada por la Vicerrectoría de Investigación', merge_format)\n",
    "    \n",
    "    # for merge cells\n",
    "    _m_range = d.get(str(end+1)) + str(start_row +1) + ':' +  d.get(str(end+len(eh))) + str(start_row +1)\n",
    "    \n",
    "    worksheet.merge_range(_m_range, 'Validación del Centro, Instituto o Corporación', merge_format)\n",
    "        \n",
    "    worksheet.set_row_pixels(start_row+1, 120)\n",
    "    #worksheet.set_column('C:C',30,general)\n",
    "    \n",
    "    # SET COLUMS BY SHEET\n",
    "    \n",
    "  '''  if:\n",
    "        worksheet.set_column(\n",
    "        '''\n",
    "    if sheet_name == '3.Integrantes grupo':\n",
    "        \n",
    "        worksheet.set_column('C:C', 10,general)\n",
    "        worksheet.set_column('D:D', 30,general)\n",
    "        worksheet.set_column('E:G', 15,general)\n",
    "        \n",
    "    elif sheet_name== 'NC_P':\n",
    "        \n",
    "        worksheet.set_column('C:C', 30,general)\n",
    "        worksheet.set_column('D:K', 20,general)\n",
    "    elif sheet_name == 'FRH_P':\n",
    "        \n",
    "        worksheet.set_column('C:C', 30,general)\n",
    "        worksheet.set_column('D:K', 20,general)\n",
    "    else:\n",
    "        worksheet.set_column('C:C', 30,general)\n",
    "        worksheet.set_column('D:K', 20,general)\n",
    "    \n",
    "    worksheet.set_column('A:A', 15)\n",
    "    worksheet.set_column('B:B', 5)\n",
    "        \n",
    "    worksheet.write(start_row+1, 0, 'VoBo de VRI', merge_format)\n",
    "    # Add a header format.\n",
    "    \n",
    "    fmt_header = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'align': 'center',    \n",
    "        'text_wrap': True,\n",
    "        'valign': 'vcenter',\n",
    "        'fg_color': '#33A584',\n",
    "        'font_color': '#FFFFFF',\n",
    "        'border': 1})\n",
    "    \n",
    "    \n",
    "    # Write the column headers with the defined format.\n",
    "    for col_num, value in enumerate(df.columns.values):\n",
    "        worksheet.write(start_row+1, col_num + 2, value, fmt_header)\n",
    "        \n",
    "    # write extra headers\n",
    "    for col_num, value in enumerate(eh):\n",
    "        worksheet.write(start_row+1, col_num + df.shape[1] + 2, value, fmt_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "interim-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_info(df, writer, sheet_name):\n",
    "    \n",
    "    '''format worksheet'''\n",
    "    \n",
    "    workbook=writer.book\n",
    "    \n",
    "    normal=workbook.add_format({'font_size':12,'text_wrap':True})\n",
    "    \n",
    "    merge_format = workbook.add_format({\n",
    "    'bold': 1,\n",
    "    'border':1,\n",
    "    'text_wrap': True,    \n",
    "    'align': 'center',\n",
    "    'valign': 'vcenter',\n",
    "    'font_color': 'black'})\n",
    "    \n",
    "    fmt_header = workbook.add_format({\n",
    "        'align': 'center',    \n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#33A584',\n",
    "        'font_color': '#FFFFFF',\n",
    "        'border': 1})\n",
    "    \n",
    "    # write df\n",
    "    start_row = 6\n",
    "    start_col = 3\n",
    "    \n",
    "    df.to_excel(writer, sheet_name, startrow =start_row, startcol=start_col,index = False)\n",
    "\n",
    "    # get worksheet object\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    \n",
    "    for col_num, value in enumerate(df.columns.values):\n",
    "        worksheet.write(start_row, col_num + 3, value, fmt_header)\n",
    "    \n",
    "    #Prepare image insertion: See → https://xlsxwriter.readthedocs.io/example_images.html\n",
    "    worksheet.set_column('A:A', 15)\n",
    "    worksheet.set_column('B:B', 15)\n",
    "    worksheet.insert_image('A1', 'img/udea.jpeg')\n",
    "    \n",
    "    # title 1 UNIVERSIDAD DE ANTIOQUIA\n",
    "    title = workbook.add_format({'font_size':16,'center_across':True})\n",
    "\n",
    "    # title 2 Vicerrectoria de Investigación\n",
    "    title2 = workbook.add_format({'font_size':16,'center_across':True})\n",
    "   \n",
    "    # sub title 2 datos identificacion contacto\n",
    "    title3 = workbook.add_format({'font_size':12,'center_across':True})\n",
    "    \n",
    "    # merge d1:f1\n",
    "    worksheet.merge_range('D1:F1', 'UNIVERSIDAD DE ANTIOQUIA', title)\n",
    "        \n",
    "    # merge d2:f2\n",
    "    worksheet.merge_range('D2:F2', ' Vicerrectoria de Investigación', title2)\n",
    "    \n",
    "    # merge d3:f3\n",
    "    worksheet.merge_range('D3:F3', ' Datos de identificación y contacto', title3)\n",
    "    \n",
    "    # D5: F5\n",
    "    worksheet.merge_range('D5:E5','Número inscripcion a la convocatoria:',merge_format)\n",
    "    worksheet.write('F5','#',merge_format)\n",
    "    \n",
    "    # d6:f6\n",
    "    worksheet.merge_range('D6:F6','Identificación del Grupo',merge_format)\n",
    "        \n",
    "    # d9:f9\n",
    "    worksheet.merge_range('D10:F10','Identificación del Centro de Investigación',merge_format)\n",
    "    # write \n",
    "    a='Nombre del Centro, Instituto o Corporación'\n",
    "    worksheet.write('D11',a, fmt_header)\n",
    "    worksheet.set_column('D11:D11',30, fmt_header)\n",
    "    \n",
    "    b='Nombre completo del Jefe de Centro, Instituto o Corporación'\n",
    "    worksheet.write('E11',b, fmt_header) \n",
    "    worksheet.set_column('E11:E11',30, fmt_header)\n",
    "    \n",
    "    c='Email'\n",
    "    worksheet.write('F11',c, fmt_header) \n",
    "    worksheet.set_column('F11:F11',30, fmt_header)\n",
    "    \n",
    "    # d13:f13\n",
    "    worksheet.merge_range('D13:F13','Identificación de quien diligencia el formato',merge_format)\n",
    "    a='Nombre completo del encargado de diligenciar el formato'\n",
    "    worksheet.write('D14',a, fmt_header)\n",
    "    worksheet.set_column('D14:D14',30, normal)\n",
    "    \n",
    "    b='Email'\n",
    "    worksheet.write('E14',b, fmt_header) \n",
    "    worksheet.set_column('E14:E14',30, normal)\n",
    "    \n",
    "    c='Teléfono de contacto'\n",
    "    worksheet.write('F14',c, fmt_header) \n",
    "    worksheet.set_column('F14:F14',30, normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "disturbed-filename",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def format_df(df, sheet_name, start_row, writer):\\n    'format headers'\\n    \\n    # Get the xlsxwriter workbook and worksheet objects.\\n    worksheet = writer.sheets[sheet_name]\\n\\n    # Add a header format.\\n    \\n    fmt_header = workbook.add_format({\\n        'bold': True,\\n        'align': 'center',    \\n        'text_wrap': True,\\n        'valign': 'top',\\n        'fg_color': '#33A584',\\n        'font_color': '#FFFFFF',\\n        'border': 1})\\n    \\n    \\n    # Write the column headers with the defined format.\\n    for col_num, value in enumerate(df.columns.values):\\n        worksheet.write(start_row, col_num + 1, value, fmt_header) # !!!\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def format_df(df, sheet_name, start_row, writer):\n",
    "    'format headers'\n",
    "    \n",
    "    # Get the xlsxwriter workbook and worksheet objects.\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "    # Add a header format.\n",
    "    \n",
    "    fmt_header = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'align': 'center',    \n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#33A584',\n",
    "        'font_color': '#FFFFFF',\n",
    "        'border': 1})\n",
    "    \n",
    "    \n",
    "    # Write the column headers with the defined format.\n",
    "    for col_num, value in enumerate(df.columns.values):\n",
    "        worksheet.write(start_row, col_num + 1, value, fmt_header) # !!!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dated-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/42370977/how-to-save-a-new-sheet-in-an-existing-excel-file-using-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bridal-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store info group in dict\n",
    "    # each key store list of tables related with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "sudden-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE GROUP IMPLEMENTATION\n",
    "idxx = 34\n",
    "\n",
    "# DATA\n",
    "DBG = LD[0]\n",
    "\n",
    "### excel name\n",
    "name = 'AA_Plantilla_Formato de verificación de información_GrupLAC_894-2021_%s'\n",
    "\n",
    "# initialize object= output excel file\n",
    "writer = pd.ExcelWriter(name % dfg.loc[idxx,'COL Grupo']+'.xlsx', engine='xlsxwriter')\n",
    "\n",
    "#Global variables\n",
    "abstract_text='VERIFICACIÓN DE INFORMACIÓN PARA OTORGAR AVAL A LOS GRUPOS DE INVESTIGACIÓN  E INVESTIGADORES PARA SU PARTICIPACIÓN EN LA CONVOCATORIA 894 DE 2021 DE MINCIENCIAS'\n",
    "instructions='''Los grupos de investigación e investigadores de la Universidad de Antioquia que deseen participar en la Convocatoria Nacional para el reconocimiento y medición de grupos de investigación, desarrollo tecnológico o de innovación y para el reconocimiento de investigadores del Sistema Nacional de Ciencia, Tecnología e Innovación - SNCTI, 894 de 2021, deben presentar la información actualizada en las plataformas CvLAC y GrupLAC validada por el Centro de Investigación en el presente formato, y respaldada en el repositorio digital de evidencias dispuesto para este fin, para la obtención del aval institucional por parte de la Vicerrectoría de Investigación. \n",
    "\n",
    "La información a validar corresponde a los años 2019-2020 y aquella que entra en la ventana de observación y debe ser modificada según el Modelo de medición de grupos. La validación comprende:\n",
    "\n",
    "1. Verificación de la vinculación de los integrantes a la Universidad de Antioquia y al grupo de investigación.  Diligenciar los campos solicitados. \n",
    "\n",
    "2. Verificación de la producción de GNC, DTeI, ASC y FRH, en los campos habilitados en cada hoja de este formato. Las evidencias requeridas para los productos deben ser anexadas al repositorio digital asignado al grupo y se deben enlazar a cada producto.  \n",
    "\n",
    "Este documento debe ser diligenciado en línea.\n",
    "\n",
    "De antemano, la Vicerrectoría de Investigación agradece su participación en este ejercicio, que resulta de vital importancia para llevar a buen término la Convocatoria de Reconocimiento y Medición de Grupos de Investigación\n",
    "'''\n",
    "#Final part of the first sheet\n",
    "datos=clean_df(pd.read_excel('https://github.com/restrepo/InstituLAC/raw/main/data/template_data.xlsx'))\n",
    "\n",
    "#Capture xlsxwriter object \n",
    "# IMPORTANT → workbook is the same object used in the official document at https://xlsxwriter.readthedocs.io\n",
    "workbook=writer.book\n",
    "#***************\n",
    "#Styles as explained in https://xlsxwriter.readthedocs.io\n",
    "general=workbook.add_format({'text_wrap':True})\n",
    "title=workbook.add_format({'font_size':28,'center_across':True})\n",
    "subtitle=workbook.add_format({'font_size':24,'center_across':True})\n",
    "abstract=workbook.add_format({'font_size':20,'center_across':True,'text_wrap':True})\n",
    "normal=workbook.add_format({'font_size':12,'text_wrap':True})\n",
    "\n",
    "merge_format = workbook.add_format({\n",
    "    'bold': 1,\n",
    "    'border':1,\n",
    "    'text_wrap': True,    \n",
    "    'align': 'center',\n",
    "    'valign': 'vcenter',\n",
    "    'font_color': 'blue'})\n",
    "\n",
    "fmt_header = workbook.add_format({\n",
    "    'bold': True,\n",
    "    'align': 'center',    \n",
    "    'text_wrap': True,\n",
    "    'valign': 'top',\n",
    "    'fg_color': '#33A584',\n",
    "    'font_color': '#FFFFFF',\n",
    "    'border': 1})\n",
    "#***************\n",
    "#Creates the first work-sheet\n",
    "#IMPORTANT → worksheet is the same object  used in the official document at https://xlsxwriter.readthedocs.io\n",
    "worksheet=workbook.add_worksheet(\"1.Presentación\")\n",
    "#Prepare image insertion: See → https://xlsxwriter.readthedocs.io/example_images.html\n",
    "worksheet.set_column('A:A', 15)\n",
    "worksheet.set_column('B:B', 15)\n",
    "worksheet.insert_image('A1', 'img/udea.jpeg')\n",
    "#Prepare text insertion: See  → https://xlsxwriter.readthedocs.io/example_images.html\n",
    "worksheet.set_column('C:C', 140,general)\n",
    "worksheet.set_row_pixels(0, 60)\n",
    "#Texts\n",
    "worksheet.write('C1', 'UNIVERSIDAD DE ANTIOQUIA',title)\n",
    "worksheet.set_row_pixels(2, 60)\n",
    "worksheet.write('C3', 'VICERRECTORÍA DE INVESTIGACIÓN',subtitle)\n",
    "worksheet.set_row_pixels(5, 100)\n",
    "worksheet.write('C6', abstract_text,abstract)\n",
    "worksheet.set_row_pixels(8, 40)\n",
    "worksheet.write('C9','PRESENTACIÓN DEL EJERCICIO',\n",
    "                workbook.add_format({'font_size':18,'center_across':True}) )\n",
    "worksheet.set_row_pixels(10, 320)\n",
    "worksheet.write('C11',instructions,normal )\n",
    "#*** ADD PANDAS DATAFRAME IN SPECIFIC POSITION ****\n",
    "#Add a data Frame in some specific position. See → https://stackoverflow.com/a/43510881/2268280\n",
    "#                                       See also → https://xlsxwriter.readthedocs.io/working_with_pandas.html\n",
    "writer.sheets[\"1.Presentación\"]=worksheet\n",
    "datos.to_excel(writer,sheet_name=\"1.Presentación\",startrow=12,startcol=2,index=False)\n",
    "#**************************************************\n",
    "#Fix columns heights for long text\n",
    "worksheet.set_row_pixels(17, 40)\n",
    "worksheet.set_row_pixels(18, 40)\n",
    "worksheet.set_row_pixels(19, 40)\n",
    "worksheet.set_row_pixels(20, 40)\n",
    "worksheet.set_row_pixels(22, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "educated-korean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Add extra headers\\nworksheet2.write(1, 0, 'VoBo de VRI', merge_format)\\n#New columns\\nextra_url='Si no tiene URL o DOI agregue una evidencia en el repositorio digital y genere un hipervínculo en este campo'\\ncols=['DOI',extra_url,'¿El producto cumple con los requisitos para ser avalado?']\\nfor col , value in enumerate(cols):\\n    worksheet2.write(1, col+2+table.columns.size, value, fmt_header)\\nworksheet2.set_column('L:L',20)\\nworksheet2.set_column('M:M',20)\\n#Creates a set of cells with a drop-down menu Sí/No. See → https://xlsxwriter.readthedocs.io/working_with_data_validation.html\\nworksheet2.data_validation('M3:M{}'.format(table.shape[0]+2), {'validate': 'list',\\n                                  'source': ['Sí', 'No']})\\n\\nworkbook.close()\\n\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Add extra headers\n",
    "worksheet2.write(1, 0, 'VoBo de VRI', merge_format)\n",
    "#New columns\n",
    "extra_url='Si no tiene URL o DOI agregue una evidencia en el repositorio digital y genere un hipervínculo en este campo'\n",
    "cols=['DOI',extra_url,'¿El producto cumple con los requisitos para ser avalado?']\n",
    "for col , value in enumerate(cols):\n",
    "    worksheet2.write(1, col+2+table.columns.size, value, fmt_header)\n",
    "worksheet2.set_column('L:L',20)\n",
    "worksheet2.set_column('M:M',20)\n",
    "#Creates a set of cells with a drop-down menu Sí/No. See → https://xlsxwriter.readthedocs.io/working_with_data_validation.html\n",
    "worksheet2.data_validation('M3:M{}'.format(table.shape[0]+2), {'validate': 'list',\n",
    "                                  'source': ['Sí', 'No']})\n",
    "\n",
    "workbook.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "purple-milan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['INFO_GROUP', 'MEMBERS', 'NC_P', 'DTI_P', 'ASC_P', 'FRH_P'])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DBEH.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "planned-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO GROUP\n",
    "df=get_info(DBG['Info_group'])\n",
    "format_info(df, writer, '2.Datos de contacto')\n",
    "\n",
    "# WORKSHEET 1\n",
    "df = clean_df(DBG['Members']) \n",
    "eh = DBEH['MEMBERS']\n",
    "format_df(df, '3.Integrantes grupo', 1, writer, eh, veh=0) #### veh = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "inappropriate-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NC_P ### WORKSHEET 2\n",
    "     \n",
    "var_nc = 0\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['ART_IMP_P']['ART_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc+1)\n",
    "    \n",
    "    eh=DBEH['NC_P']['ART_IMP_P']['ART_P_TABLE']\n",
    "\n",
    "    format_df(df, 'NC_P', var_nc, writer,eh)\n",
    "        \n",
    "    var_nc += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['ART_ELE_P']['ART_E_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['ART_ELE_P']['ART_E_P_TABLE']\n",
    "\n",
    "    format_df(df, 'NC_P', var_nc, writer,eh)\n",
    "        \n",
    "    var_nc += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['LIB_P']['LIB_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['LIB_P']['LIB_P_TABLE']\n",
    "\n",
    "    format_df(df, 'NC_P', var_nc, writer,eh)\n",
    "        \n",
    "    var_nc += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['CAP_LIB_P']['CAP_LIB_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['CAP_LIB_P']['CAP_LIB_P_TABLE']\n",
    "\n",
    "    format_df(df, 'NC_P', var_nc, writer,eh)\n",
    "        \n",
    "    var_nc += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['NOT_CIE_P']['NOT_CIE_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['NOT_CIE_P']['NOT_CIE_P_TABLE']\n",
    "\n",
    "    format_df(df, 'NC_P', var_nc, writer,eh)\n",
    "        \n",
    "    var_nc += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['PAT_P']['PAT_P_TABLE']) ###### veh=1\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['PAT_P']['PAT_P_TABLE']\n",
    "\n",
    "    format_df(df, 'NC_P', var_nc, writer,eh, veh=1)\n",
    "        \n",
    "    var_nc += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['PRD_INV_ART_P']['PAAD_P_TABLE']) ###### veh = 1\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['PRD_INV_ART_P']['PAAD_P_TABLE']\n",
    "\n",
    "    format_df(df, 'NC_P', var_nc, writer,eh, veh=1)\n",
    "        \n",
    "    var_nc += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['VAR_VEG_P']['VV_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['VAR_VEG_P']['VV_P_TABLE']\n",
    "\n",
    "    format_df(df, 'NC_P', var_nc, writer,eh)\n",
    "        \n",
    "    var_nc += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['VAR_ANI_P']['VA_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['VAR_ANI_P']['VA_P_TABLE']\n",
    "\n",
    "    format_df(df, 'NC_P', var_nc, writer,eh)\n",
    "        \n",
    "    var_nc += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['RAZ_PEC_P']['RAZ_PEC_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['RAZ_PEC_P']['RAZ_PEC_P_TABLE']\n",
    "\n",
    "    format_df(df, 'NC_P', var_nc, writer,eh)\n",
    "        \n",
    "    var_nc += df.shape[0] + 3\n",
    "\n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['NC_P']['TRA_FIL_P']['TRA_FIL_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='NC_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['NC_P']['TRA_FIL_P']['TRA_FIL_P_TABLE']\n",
    "\n",
    "    format_df(df, 'NC_P', var_nc, writer,eh)\n",
    "        \n",
    "    var_nc += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "#### DTI_P\n",
    "\n",
    "var_dt = 0\n",
    "try:\n",
    "\n",
    "    df=clean_df(DBG['DTI_P']['DIS_IND_P']['DI_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['DIS_IND_P']['DI_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['CIR_INT_P']['ECI_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['CIR_INT_P']['ECI_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['SOFT_P']['SF_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['SOFT_P']['SF_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['NUTRA_P']['NUTRA_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_nc)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['NUTRA_P']['NUTRA_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['COL_CIENT_P']['COL_CIENT_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['COL_CIENT_P']['COL_CIENT_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['REG_CIENT_P']['REG_CIENT_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['REG_CIENT_P']['REG_CIENT_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['PLT_PIL_P']['PP_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['PLT_PIL_P']['PP_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['PRT_IND_P']['PI_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['PRT_IND_P']['PI_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['SEC_IND_P']['SE_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['SEC_IND_P']['SE_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['PROT_VIG_EPID_P']['PROT_VIG_EPID_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['PROT_VIG_EPID_P']['PROT_VIG_EPID_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['EMP_BSE_TEC_P']['EBT_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['EMP_BSE_TEC_P']['EBT_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['EMP_CRE_CUL_P']['ICC_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['EMP_CRE_CUL_P']['ICC_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['INN_GES_EMP_P']['IG_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['INN_GES_EMP_P']['IG_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['INN_PROC_P']['IPP_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['INN_PROC_P']['IPP_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['REG_NORM_REGL_LEG_P']['RNR_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['REG_NORM_REGL_LEG_P']['RNR_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['CONP_TEC_P']['CONP_TEC_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['CONP_TEC_P']['CONP_TEC_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['REG_AAD_P']['AAAD_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['REG_AAD_P']['AAAD_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['DTI_P']['SIG_DIS_P']['SD_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='DTI_P',startrow = var_dt)\n",
    "    \n",
    "    eh=DBEH['DTI_P']['SIG_DIS_P']['SD_P_TABLE']\n",
    "\n",
    "    format_df(df, 'DTI_P', var_dt, writer,eh)\n",
    "        \n",
    "    var_dt += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "######  ASC\n",
    "\n",
    "var_as = 0\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['GEN_CONT_IMP_P']['GC_I_P_TABLE_5'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['GEN_CONT_IMP_P']['GC_I_P_TABLE_5']\n",
    "\n",
    "    format_df(df, 'ASC_P', var_as, writer,eh)\n",
    "        \n",
    "    var_as += df.shape[0] + 3\n",
    "    \n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass                  \n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['PASC_P']['PASC_FOR_P_TABLE'])\n",
    "    \n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['GEN_CONT_IMP_P']['GC_I_P_TABLE_5']\n",
    "\n",
    "    format_df(df, 'ASC_P', var_as, writer,eh)\n",
    "        \n",
    "    var_as += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['PASC_P']['PASC_TRA_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['PASC_P']['PASC_TRA_P_TABLE']\n",
    "\n",
    "    format_df(df, 'ASC_P', var_as, writer,eh)\n",
    "        \n",
    "    var_as += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['PASC_P']['PASC_GEN_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['PASC_P']['PASC_GEN_P_TABLE']\n",
    "\n",
    "    format_df(df, 'ASC_P', var_as, writer,eh)\n",
    "        \n",
    "    var_as += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['PASC_P']['PASC_CAD_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['PASC_P']['PASC_CAD_P_TABLE']\n",
    "\n",
    "    format_df(df, 'ASC_P', var_as, writer,eh)\n",
    "        \n",
    "    var_as += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['DC_P']['DC_CD_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['DC_P']['DC_CD_P_TABLE']\n",
    "\n",
    "    format_df(df, 'ASC_P', var_as, writer,eh)\n",
    "        \n",
    "    var_as += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['DC_P']['DC_CON_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['DC_P']['DC_CON_P_TABLE']\n",
    "\n",
    "    format_df(df, 'ASC_P', var_as, writer,eh)\n",
    "        \n",
    "    var_as += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['DC_P']['DC_TRA_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['DC_P']['DC_TRA_P_TABLE']\n",
    "\n",
    "    format_df(df, 'ASC_P', var_as, writer,eh)\n",
    "        \n",
    "    var_as += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['ASC_P']['DC_P']['DC_TRA_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='ASC_P',startrow = var_as)\n",
    "    \n",
    "    eh=DBEH['ASC_P']['DC_P']['DC_TRA_P_TABLE']\n",
    "\n",
    "    format_df(df, 'ASC_P', var_as, writer,eh)\n",
    "        \n",
    "    var_as += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "# FRH\n",
    "\n",
    "var_rh = 0\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['FRH_P']['TES_DOC_P']['TD_P_TABLE'])  ### ,veh = 2\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='FRH_P',startrow = var_rh)\n",
    "    \n",
    "    eh=DBEH['FRH_P']['TES_DOC_P']['TD_P_TABLE']\n",
    "\n",
    "    format_df(df, 'FRH_P', var_rh, writer, eh)\n",
    "        \n",
    "    var_rh += df.shape[0] + 3\n",
    "\n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['FRH_P']['TES_MAST_P']['TM_P_TABLE']) ### veh = 2\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='FRH_P',startrow = var_rh)\n",
    "    \n",
    "    eh=DBEH['FRH_P']['TES_MAST_P']['TM_P_TABLE']\n",
    "\n",
    "    format_df(df, 'FRH_P', var_rh, writer,eh)\n",
    "        \n",
    "    var_rh += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['FRH_P']['TES_PREG_P']['TP_P_TABLE']) ### veh = 2\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='FRH_P',startrow = var_rh)\n",
    "    \n",
    "    eh=DBEH['FRH_P']['TES_PREG_P']['TP_P_TABLE']\n",
    "\n",
    "    format_df(df, 'FRH_P', var_rh, writer,eh,veh = 2)\n",
    "        \n",
    "    var_rh += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['FRH_P']['ASE_PRG_ACA_P']['APGA_P_TABLE']) \n",
    "\n",
    "    #df.to_excel(writer,sheet_name='FRH_P',startrow = var_rh)\n",
    "    \n",
    "    eh=DBEH['FRH_P']['ASE_PRG_ACA_P']['APGA_P_TABLE']\n",
    "\n",
    "    format_df(df, 'FRH_P', var_rh, writer,eh)\n",
    "        \n",
    "    var_rh += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['FRH_P']['ASE_CRE_CUR_P']['ACC_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='FRH_P',startrow = var_rh)\n",
    "    \n",
    "    eh=DBEH['FRH_P']['ASE_CRE_CUR_P']['ACC_P_TABLE']\n",
    "\n",
    "    format_df(df, 'FRH_P', var_rh, writer,eh)\n",
    "        \n",
    "    var_rh += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df=clean_df(DBG['FRH_P']['ASE_PRG_ONDAS_P']['APO_P_TABLE'])\n",
    "\n",
    "    #df.to_excel(writer,sheet_name='FRH_P',startrow = var_rh)\n",
    "    \n",
    "    eh=DBEH['FRH_P']['ASE_PRG_ONDAS_P']['APO_P_TABLE']\n",
    "\n",
    "    format_df(df, 'FRH_P', var_rh, writer,eh)\n",
    "        \n",
    "    var_rh += df.shape[0] + 3\n",
    "    \n",
    "except KeyError as e:\n",
    "    \n",
    "    pass\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-colors",
   "metadata": {},
   "source": [
    "# ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "settled-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "schema for store tables\n",
    "\n",
    "DBG = {\n",
    "    \n",
    "    'INFO_GROUP': 'TABLE',\n",
    "    'MEMBERS':'TABLE',\n",
    "       \n",
    "    'NC_P': {'ART_IMP_P': {'ART_P_TABLE':'TABLE'},\n",
    "             'ART_ELE_P': {'ART_E_P_TABLE':'TABLE'},\n",
    "             'LIB_P':     {'LIB_P_TABLE':'TABLE'},\n",
    "             'CAP_LIB_P': {'CAP_LIB_P_TABLE':'TABLE'},\n",
    "             'NOT_CIE_P': {'NOT_CIE_P_TABLE':'TABLE'},\n",
    "             'PAT_P':     {'PAT_P_TABLE':'TABLE'},\n",
    "             'PRD_INV_ART_P': {'PAAD_P_TABLE':'TABLE'},\n",
    "             'VAR_VEG_P':     {'VV_P_TABLE':'TABLE'},\n",
    "             'VAR_ANI_P':     {'VA_P_TABLE':'TABLE'},\n",
    "             'RAZ_PEC_P':     {'RAZ_PEC_P_TABLE':'TABLE'},\n",
    "             'TRA_FIL_P': {'TRA_FIL_P_TABLE':'TABLE'}\n",
    "            },\n",
    "     'DTI_P': {'DIS_IND_P': {'DI_P_TABLE':'TABLE'},\n",
    "              'CIR_INT_P': {'ECI_P_TABLE':'TABLE'},\n",
    "              'SOFT_P': {'SF_P_TABLE':'TABLE'},\n",
    "              'NUTRA_P': {'NUTRA_P_TABLE':'TABLE'},\n",
    "              'COL_CIENT_P': {'COL_CIENT_P_TABLE':'TABLE'},\n",
    "              'REG_CIENT_P': {'REG_CIENT_P_TABLE':'TABLE'},\n",
    "              'PLT_PIL_P': {'PP_P_TABLE':'TABLE'},\n",
    "              'PRT_IND_P': {'PI_P_TABLE':'TABLE'},\n",
    "              'SEC_IND_P': {'SE_P_TABLE':'TABLE'},\n",
    "              'PROT_VIG_EPID_P': {'PROT_VIG_EPID_P_TABLE':'TABLE'},\n",
    "              'EMP_BSE_TEC_P': {'EBT_P_TABLE':'TABLE'},\n",
    "              'EMP_CRE_CUL_P': {'ICC_P_TABLE':'TABLE'},\n",
    "              'INN_GES_EMP_P': {'IG_P_TABLE':'TABLE'},\n",
    "              'INN_PROC_P': {'IPP_P_TABLE':'TABLE'},\n",
    "              'REG_NORM_REGL_LEG_P': {'RNR_P_TABLE':'TABLE'},\n",
    "              'CONP_TEC_P': {'CONP_TEC_P_TABLE':'TABLE'},\n",
    "              'REG_AAD_P': {'AAAD_P_TABLE':'TABLE'},\n",
    "              'SIG_DIS_P': {'SD_P_TABLE':'TABLE'}\n",
    "              },\n",
    "    'ASC_P': {'GEN_CONT_IMP_P': {'GC_I_P_TABLE_5':'TABLE'},\n",
    "              'PASC_P': {'PASC_FOR_P_TABLE':'TABLE',\n",
    "               'PASC_TRA_P_TABLE':'TABLE',\n",
    "               'PASC_GEN_P_TABLE':'TABLE',\n",
    "               'PASC_CAD_P_TABLE':'TABLE'},\n",
    "              'DC_P': {'DC_CD_P_TABLE':'TABLE',\n",
    "               'DC_CON_P_TABLE':'TABLE',\n",
    "               'DC_TRA_P_TABLE':'TABLE',\n",
    "               'DC_TRA_P_TABLE':'TABLE'}},\n",
    "    'FRH_P': {'TES_DOC_P': {'TD_P_TABLE':'TABLE'},\n",
    "              'TES_MAST_P': {'TM_P_TABLE':'TABLE'},\n",
    "              'TES_PREG_P': {'TP_P_TABLE':'TABLE'},\n",
    "              'PROY_INV_DES_P': {'PID_P_TABLE':'TABLE'},\n",
    "              'PROY_INV_CRE_P': {'INV_CRE_P_TABLE':'TABLE'},\n",
    "              'PROY_INV_DES_INN_P': {'PF_P_TABLE':'TABLE'},\n",
    "              'PROY_INV_RESP_SOC_P': {'PE_P_TABLE':'TABLE'},\n",
    "              'ASE_PRG_ACA_P': {'APGA_P_TABLE':'TABLE'},\n",
    "              'ASE_CRE_CUR_P': {'ACC_P_TABLE':'TABLE'},\n",
    "              'ASE_PRG_ONDAS_P': {'APO_P_TABLE':'TABLE'}}\n",
    "}'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
